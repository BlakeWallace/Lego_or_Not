{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw   # Python Reddit API Wrapper\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6 Months, 150,000 Pieces, 200 LEDs Later... My...</td>\n",
       "      <td>1261</td>\n",
       "      <td>b31lgu</td>\n",
       "      <td>https://i.redd.it/18yfvmxul4n21.jpg</td>\n",
       "      <td>46</td>\n",
       "      <td>1.553023e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-19 14:20:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sorry if it’s been done before but i thought i...</td>\n",
       "      <td>790</td>\n",
       "      <td>aqb5c7</td>\n",
       "      <td>https://i.redd.it/6fqwr1q4ceg21.jpg</td>\n",
       "      <td>40</td>\n",
       "      <td>1.550090e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-13 14:34:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars Battlefront 2 Vardos Tower WIP. Me f...</td>\n",
       "      <td>763</td>\n",
       "      <td>axcpto</td>\n",
       "      <td>https://i.redd.it/ryvf1n4786k21.jpg</td>\n",
       "      <td>44</td>\n",
       "      <td>1.551735e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-04 15:34:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Current version of all my Box MOCs!</td>\n",
       "      <td>764</td>\n",
       "      <td>asz3n8</td>\n",
       "      <td>https://i.redd.it/lyhhr4x2uuh21.jpg</td>\n",
       "      <td>47</td>\n",
       "      <td>1.550726e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-20 23:07:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I hope you guys can appreciate my venator MOC</td>\n",
       "      <td>718</td>\n",
       "      <td>az818i</td>\n",
       "      <td>https://i.redd.it/46z1vsuiq5l21.jpg</td>\n",
       "      <td>27</td>\n",
       "      <td>1.552165e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-09 14:59:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  6 Months, 150,000 Pieces, 200 LEDs Later... My...   1261  b31lgu   \n",
       "1  Sorry if it’s been done before but i thought i...    790  aqb5c7   \n",
       "2  Star Wars Battlefront 2 Vardos Tower WIP. Me f...    763  axcpto   \n",
       "3                Current version of all my Box MOCs!    764  asz3n8   \n",
       "4      I hope you guys can appreciate my venator MOC    718  az818i   \n",
       "\n",
       "                                   url  comms_num       created body  \\\n",
       "0  https://i.redd.it/18yfvmxul4n21.jpg         46  1.553023e+09  NaN   \n",
       "1  https://i.redd.it/6fqwr1q4ceg21.jpg         40  1.550090e+09  NaN   \n",
       "2  https://i.redd.it/ryvf1n4786k21.jpg         44  1.551735e+09  NaN   \n",
       "3  https://i.redd.it/lyhhr4x2uuh21.jpg         47  1.550726e+09  NaN   \n",
       "4  https://i.redd.it/46z1vsuiq5l21.jpg         27  1.552165e+09  NaN   \n",
       "\n",
       "        category  class            timestamp  \n",
       "0  top_subreddit      1  2019-03-19 14:20:28  \n",
       "1  top_subreddit      1  2019-02-13 14:34:38  \n",
       "2  top_subreddit      1  2019-03-04 15:34:59  \n",
       "3  top_subreddit      1  2019-02-20 23:07:54  \n",
       "4  top_subreddit      1  2019-03-09 14:59:58  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = pd.read_csv('data_pos_class.csv')\n",
    "positive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guardians of the Front Page</td>\n",
       "      <td>283477</td>\n",
       "      <td>5gn8ru</td>\n",
       "      <td>http://i.imgur.com/OOFRJvr.gifv</td>\n",
       "      <td>5024</td>\n",
       "      <td>1.480960e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-05 11:41:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks, Obama.</td>\n",
       "      <td>230830</td>\n",
       "      <td>5bx4bx</td>\n",
       "      <td>https://i.reddituploads.com/58986555f545487c9d...</td>\n",
       "      <td>6116</td>\n",
       "      <td>1.478651e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-08 18:27:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am Barack Obama, President of the United Sta...</td>\n",
       "      <td>216141</td>\n",
       "      <td>z1c9z</td>\n",
       "      <td>https://www.reddit.com/r/IAmA/comments/z1c9z/i...</td>\n",
       "      <td>23255</td>\n",
       "      <td>1.346270e+09</td>\n",
       "      <td>Hi, I’m Barack Obama, President of the United ...</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-29 15:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is Shelia Fredrick, a flight attendant. S...</td>\n",
       "      <td>222814</td>\n",
       "      <td>5sfexx</td>\n",
       "      <td>https://i.reddituploads.com/d1e77b5c62694624ba...</td>\n",
       "      <td>4370</td>\n",
       "      <td>1.486401e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-06 11:06:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 dad reflex 2 children</td>\n",
       "      <td>204183</td>\n",
       "      <td>5jrlw1</td>\n",
       "      <td>http://i.imgur.com/Rum0zSz.gifv</td>\n",
       "      <td>5674</td>\n",
       "      <td>1.482426e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>top_subreddit</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-22 10:57:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   score      id  \\\n",
       "0                        Guardians of the Front Page  283477  5gn8ru   \n",
       "1                                     Thanks, Obama.  230830  5bx4bx   \n",
       "2  I am Barack Obama, President of the United Sta...  216141   z1c9z   \n",
       "3  This is Shelia Fredrick, a flight attendant. S...  222814  5sfexx   \n",
       "4                            1 dad reflex 2 children  204183  5jrlw1   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0                    http://i.imgur.com/OOFRJvr.gifv       5024  1.480960e+09   \n",
       "1  https://i.reddituploads.com/58986555f545487c9d...       6116  1.478651e+09   \n",
       "2  https://www.reddit.com/r/IAmA/comments/z1c9z/i...      23255  1.346270e+09   \n",
       "3  https://i.reddituploads.com/d1e77b5c62694624ba...       4370  1.486401e+09   \n",
       "4                    http://i.imgur.com/Rum0zSz.gifv       5674  1.482426e+09   \n",
       "\n",
       "                                                body       category  class  \\\n",
       "0                                                NaN  top_subreddit      0   \n",
       "1                                                NaN  top_subreddit      0   \n",
       "2  Hi, I’m Barack Obama, President of the United ...  top_subreddit      0   \n",
       "3                                                NaN  top_subreddit      0   \n",
       "4                                                NaN  top_subreddit      0   \n",
       "\n",
       "             timestamp  \n",
       "0  2016-12-05 11:41:14  \n",
       "1  2016-11-08 18:27:25  \n",
       "2  2012-08-29 15:01:36  \n",
       "3  2017-02-06 11:06:40  \n",
       "4  2016-12-22 10:57:35  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df = pd.read_csv('data_neg_class.csv')\n",
    "negative_df['class'] = negative_df['class'].map(lambda x:0)\n",
    "negative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([positive_df, negative_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13081, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6 Months, 150,000 Pieces, 200 LEDs Later... My...\n",
       "1    Sorry if it’s been done before but i thought i...\n",
       "2    Star Wars Battlefront 2 Vardos Tower WIP. Me f...\n",
       "3                  Current version of all my Box MOCs!\n",
       "4        I hope you guys can appreciate my venator MOC\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6541\n",
       "1    6540\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our classes are balanced\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000382233774177"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the baseline accuracy we desire is \n",
    "max(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split (before doing any transformations or cleaning of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9810,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-753d30228bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0mgs_ada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mada_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgs_ada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_ada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_ada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "ada_params = {\n",
    "    'n_estimators': [100],\n",
    "    'base_estimator__max_depth': [2],\n",
    "    'learning_rate': [1.]\n",
    "}\n",
    "gs_ada = GridSearchCV(ada, param_grid=ada_params, cv=5)\n",
    "gs_ada.fit(df_train, y_train)\n",
    "print(gs_ada.best_score_)\n",
    "print(gs_ada.best_params_)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ada.score(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122898196270254"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ada.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-77961ef8b4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0mgs_ada1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mada1_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgs_ada1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_ada1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_ada1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ada1 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "ada1_params = {\n",
    "    'base_estimator__max_depth': [None, 2],\n",
    "    'n_estimators': [25, 50],\n",
    "    'learning_rate': [.7, .8, 1.0]\n",
    "}\n",
    "gs_ada1 = GridSearchCV(ada1, param_grid=ada1_params, cv=5)\n",
    "gs_ada1.fit(df_train, y_train)\n",
    "print(gs_ada1.best_score_)\n",
    "print(gs_ada1.best_params_)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ada1.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ada_lr = AdaBoostClassifier(base_estimator=LogisticRegression())\n",
    "ada_lr_params = {\n",
    "    'n_estimators': [50,100],\n",
    "    'base_estimator__max_depth': [1,2],\n",
    "    'learning_rate': [.9, 1.]\n",
    "}\n",
    "gs_ada_lr = GridSearchCV(ada, param_grid=ada_lr_params, cv=3)\n",
    "gs_ada_lr.fit(df_train, y_train)\n",
    "print(gs_ada_lr.best_score_)\n",
    "print(gs_ada_lr.best_params_)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ada_lr.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(lr, param_grid=lr_params, cv=5)\n",
    "gs_lr.fit(df_train, y_train)\n",
    "print(gs_lr.best_score_)\n",
    "print(gs_lr.best_params_)\n",
    "\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>105</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zelda</th>\n",
       "      <th>zepher</th>\n",
       "      <th>zero</th>\n",
       "      <th>zion</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  001  10  100  1000  105  11  12  120  ...  zealand  zebra  zelda  \\\n",
       "0   0    0    0   0    0     0    0   0   0    0  ...        0      0      0   \n",
       "1   0    0    0   0    0     0    0   0   0    0  ...        0      0      0   \n",
       "2   0    0    0   0    0     0    0   0   0    0  ...        0      0      0   \n",
       "3   0    0    0   0    0     0    0   0   0    0  ...        0      0      0   \n",
       "4   0    0    0   0    0     0    0   0   0    0  ...        0      0      0   \n",
       "\n",
       "   zepher  zero  zion  zip  zombie  zone  zoo  \n",
       "0       0     0     0    0       0     0    0  \n",
       "1       0     0     0    0       0     0    0  \n",
       "2       0     0     0    0       0     0    0  \n",
       "3       0     0     0    0       0     0    0  \n",
       "4       0     0     0    0       0     0    0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': [1,3,4,5,15,21],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "gs_knn = GridSearchCV(\n",
    "    knn, \n",
    "    knn_params, \n",
    "    #scoring = scorer, \n",
    "    verbose = 1,\n",
    "    cv=3\n",
    ")\n",
    "gs_knn.fit(df_train, y_train)\n",
    "print(gs_knn.best_score_)\n",
    "print(gs_knn.best_params_)\n",
    "\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800407747196738\n",
      "{'max_depth': None, 'max_features': 2, 'n_estimators': 100}\n",
      "time: 237.061 seconds\n",
      "time: 3 minutes, 57.061 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [10, 20, 30, 50, 100],\n",
    "    'max_depth': [None, 2, 3, 5, 10],\n",
    "    'max_features': [2]#'auto', 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "gs_rf = GridSearchCV(\n",
    "    rf, \n",
    "    param_grid=rf_params, \n",
    "    #scoring = scorer, \n",
    "    verbose = 1\n",
    ")\n",
    "gs_rf.fit(df_train, y_train)\n",
    "print(gs_rf.best_score_)\n",
    "print(gs_rf.best_params_)\n",
    "\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.980428134556575"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.score(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208498929990828"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9389398572884812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81381840415775"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "# rf_params = {\n",
    "#     'base_estimator__n_estimators': [100],\n",
    "#     'base_estimator__max_depth': [None],\n",
    "#     'base_estimator__max_features': [2]\n",
    "# }\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=100, max_depth=None, max_features=2), \n",
    "                        n_estimators=2)\n",
    "bag.fit(df_train, y_train)\n",
    "print(bag.score(df_train, y_train))\n",
    "bag.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9559633027522936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8287985325588505"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "# rf_params = {\n",
    "#     'base_estimator__n_estimators': [100],\n",
    "#     'base_estimator__max_depth': [None],\n",
    "#     'base_estimator__max_features': [2]\n",
    "# }\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=RandomForestClassifier(n_estimators=100, max_depth=None, max_features=2), \n",
    "                        n_estimators=4)\n",
    "bag.fit(df_train, y_train)\n",
    "print(bag.score(df_train, y_train))\n",
    "bag.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9229357798165138\n",
      "0.8132069703454601\n",
      "time: 123.209 seconds\n",
      "time: 2 minutes, 3.209 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "bag_params = {\n",
    "    'n_estimators': [1],\n",
    "    'max_depth': [1],\n",
    "    'base_estimator': [None, RandomForestClassifier(n_estimators=100, max_depth=None, max_features=2)]\n",
    "}\n",
    "\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(gs_bag.score(df_train, y_train))\n",
    "print(gs_bag.score(df_test, y_test))\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=1, n_jobs=None, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features=2, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False), 'n_estimators': 1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9668705402650357\n",
      "0.8318557016202996\n",
      "time: 793.912 seconds\n",
      "time: 13 minutes, 13.912 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "bag_params = {\n",
    "    'base_estimator__n_estimators': [100],\n",
    "    'base_estimator__max_depth': [2, None],\n",
    "    'base_estimator__max_features': [2]\n",
    "#     'base_estimator': [None, RandomForestClassifier(n_estimators=100, max_depth=None, max_features=2)]\n",
    "}\n",
    "\n",
    "bag = BaggingClassifier(RandomForestClassifier())\n",
    "\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(gs_bag.score(df_train, y_train))\n",
    "print(gs_bag.score(df_test, y_test))\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/4/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw   # Python Reddit API Wrapper\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thank you for your function, Heather\n",
    "\n",
    "def metrics(y_test, y_predict):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Actually_Negative', 'Actually_Positive'], \n",
    "                            columns=['Predicted_Negative', 'Predicted_Positive']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.read_csv('data_pos_class.csv')\n",
    "# positive_df.head()\n",
    "\n",
    "negative_df = pd.read_csv('data_neg_class.csv')\n",
    "negative_df['class'] = negative_df['class'].map(lambda x:0)\n",
    "# negative_df.head()\n",
    "\n",
    "df = pd.concat([positive_df, negative_df], axis=0)\n",
    "df.shape\n",
    "\n",
    "X = df['title']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This train test split uses a much smaller testing set.\n",
    "# train/test split (before doing any transformations or cleaning of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10464,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams = 1 or 2\n",
    "# We use less max features, to see if we cannot reduce some of the variance\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=4000, ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.9625382262996942\n",
      "The testing score: 0.8318685517768437\n",
      "Generating predictions\n",
      "time: 802.774 seconds\n",
      "time: 13 minutes, 22.774 seconds\n",
      "Accuracy score 0.8318685517768437  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1192                 117\n",
      "Actually_Positive                 323                 985 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84      1309\n",
      "           1       0.89      0.75      0.82      1308\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      2617\n",
      "   macro avg       0.84      0.83      0.83      2617\n",
      "weighted avg       0.84      0.83      0.83      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator__n_estimators': [100],\n",
    "    'base_estimator__max_depth': [2, None],\n",
    "    'base_estimator__max_features': [2]\n",
    "#     'base_estimator': [None, RandomForestClassifier(n_estimators=100, max_depth=None, max_features=2)]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier(RandomForestClassifier())\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This train test split uses a much smaller testing set.\n",
    "# train/test split (before doing any transformations or cleaning of the data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() \n",
    "model = nb.fit(df_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8800649847094801"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8429499426824608"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(df_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8429499426824608  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1173                 136\n",
      "Actually_Positive                 275                1033 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      1309\n",
      "           1       0.88      0.79      0.83      1308\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2617\n",
      "   macro avg       0.85      0.84      0.84      2617\n",
      "weighted avg       0.85      0.84      0.84      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 1173\n",
      "False Positives: 136\n",
      "False Negatives: 275\n",
      "True Positives: 1033\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alliance\n",
      "allow\n",
      "allowance\n",
      "allowed\n",
      "alpha\n",
      "alright\n",
      "alternate\n",
      "alternate build\n",
      "alternative\n",
      "alternative build\n",
      "ama\n",
      "amazing\n",
      "amazing lego\n",
      "amazon\n",
      "america\n",
      "american\n",
      "americans\n",
      "anakin\n",
      "ancient\n",
      "android\n",
      "angle\n",
      "angry\n",
      "animal\n",
      "animals\n",
      "animated\n",
      "animation\n",
      "anniversary\n",
      "anniversary sets\n",
      "anniversary slave\n",
      "announced\n",
      "announcement\n",
      "announces\n",
      "answer\n",
      "anti\n",
      "anybody\n",
      "anybody know\n",
      "anybody remember\n",
      "anymore\n",
      "ap\n",
      "apart\n",
      "apartment\n",
      "apocalypse\n",
      "apollo\n",
      "apologize\n",
      "app\n",
      "apparently\n",
      "appear\n",
      "apple\n",
      "appreciate\n",
      "appreciated\n",
      "appropriate\n",
      "apr\n",
      "april\n",
      "april 2019\n",
      "april fools\n",
      "arab\n",
      "arabia\n",
      "arc\n",
      "arcade\n",
      "architecture\n",
      "area\n",
      "aren\n",
      "arizona\n",
      "arm\n",
      "armed\n",
      "armor\n",
      "arms\n",
      "army\n",
      "arrest\n",
      "arrested\n",
      "arrived\n",
      "arrived today\n",
      "art\n",
      "article\n",
      "artist\n",
      "artists\n",
      "artwork\n",
      "ask\n",
      "asked\n",
      "asking\n",
      "asks\n",
      "asleep\n",
      "ass\n",
      "assault\n",
      "assault walker\n",
      "asshole\n",
      "astromech\n",
      "ate\n",
      "athene\n",
      "athletes\n",
      "atm\n",
      "attached\n",
      "attack\n",
      "attacked\n",
      "attempt\n",
      "attempting\n",
      "attention\n",
      "attic\n",
      "audience\n",
      "august\n",
      "aunt\n",
      "australia\n",
      "australians\n",
      "autism\n",
      "autumn\n",
      "availability\n",
      "available\n",
      "avengers\n",
      "avengers infinity\n",
      "average\n",
      "awaiting\n",
      "awakens\n",
      "awakens review\n",
      "award\n",
      "awards\n",
      "awareness\n",
      "away\n",
      "awesome\n",
      "awesome lego\n",
      "awhile\n",
      "aww\n",
      "babies\n",
      "baby\n",
      "background\n",
      "backlog\n",
      "backwards\n",
      "backyard\n",
      "bad\n",
      "bad ass\n",
      "bad boy\n",
      "bad boys\n",
      "bad guys\n",
      "bad quality\n",
      "badass\n",
      "bag\n",
      "bags\n",
      "bakery\n",
      "balcony\n",
      "ball\n",
      "balls\n",
      "ban\n",
      "banana\n",
      "banana scale\n",
      "band\n",
      "bang\n",
      "bank\n",
      "banned\n",
      "bans\n",
      "bar\n",
      "barbie\n",
      "barc\n",
      "barc speeder\n",
      "barcelona\n",
      "bardstown\n",
      "bardstown ky\n",
      "barn\n",
      "barnes\n",
      "barry\n",
      "bars\n",
      "base\n",
      "base moc\n",
      "baseball\n",
      "based\n",
      "basement\n",
      "basically\n",
      "basketball\n",
      "bastard\n",
      "bat\n",
      "batcave\n",
      "bathroom\n",
      "batman\n",
      "batman movie\n",
      "batmobile\n",
      "battle\n",
      "battle pack\n",
      "battle packs\n",
      "battlefront\n",
      "battlepack\n",
      "bay\n",
      "bb\n",
      "beach\n",
      "bean\n",
      "bear\n",
      "beard\n",
      "beast\n",
      "beat\n",
      "beatles\n",
      "beats\n",
      "beautiful\n",
      "beautiful view\n",
      "beauty\n",
      "bed\n",
      "beer\n",
      "beetle\n",
      "begin\n",
      "beginning\n",
      "begins\n",
      "behold\n",
      "believe\n",
      "bell\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(df_train.columns[200 + i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue>\n",
    "    ngrams = 1, 2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This train test split uses a much smaller testing set.\n",
    "# train/test split (before doing any transformations or cleaning of the data)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X, y,\n",
    "                                                    random_state = 17,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10464,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams = 1, 2, or3\n",
    "# We use less max features, to see if we cannot reduce some of the variance\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec3 = CountVectorizer(max_features=4000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df3_train = pd.DataFrame(cvec3.fit_transform(X3_train).toarray(),\n",
    "                        columns=cvec3.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df3_test = pd.DataFrame(cvec3.transform(X3_test).toarray(),\n",
    "                      columns=cvec3.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb3 = MultinomialNB() \n",
    "model3 = nb3.fit(df3_train, y3_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = nb3.predict(df3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8798738532110092"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb3.score(df3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853649216660298"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb3.score(df3_test, y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_state: 0\n",
      "Training accuracy: 0.8798738532110092\n",
      "Testing accuracy: 0.834543370271303\n",
      "\n",
      "Random_state: 1\n",
      "Training accuracy: 0.8778669724770642\n",
      "Testing accuracy: 0.8479174627435996\n",
      "\n",
      "Random_state: 2\n",
      "Training accuracy: 0.8791093272171254\n",
      "Testing accuracy: 0.8528849828047382\n",
      "\n",
      "Random_state: 3\n",
      "Training accuracy: 0.8812117737003058\n",
      "Testing accuracy: 0.8353076041268628\n",
      "\n",
      "Random_state: 4\n",
      "Training accuracy: 0.880447247706422\n",
      "Testing accuracy: 0.8418035918991211\n",
      "\n",
      "Random_state: 5\n",
      "Training accuracy: 0.8776758409785933\n",
      "Testing accuracy: 0.8356897210546427\n",
      "\n",
      "Random_state: 6\n",
      "Training accuracy: 0.8805428134556575\n",
      "Testing accuracy: 0.8414214749713412\n",
      "\n",
      "Random_state: 7\n",
      "Training accuracy: 0.8817851681957186\n",
      "Testing accuracy: 0.8234619793656859\n",
      "\n",
      "Random_state: 8\n",
      "Training accuracy: 0.8837920489296636\n",
      "Testing accuracy: 0.8269010317157051\n",
      "\n",
      "Random_state: 9\n",
      "Training accuracy: 0.8774847094801224\n",
      "Testing accuracy: 0.838746656476882\n",
      "\n",
      "Random_state: 10\n",
      "Training accuracy: 0.8807339449541285\n",
      "Testing accuracy: 0.8322506687046236\n",
      "\n",
      "Random_state: 11\n",
      "Training accuracy: 0.8779625382262997\n",
      "Testing accuracy: 0.8467711119602599\n",
      "\n",
      "Random_state: 12\n",
      "Training accuracy: 0.8784403669724771\n",
      "Testing accuracy: 0.8391287734046619\n",
      "\n",
      "Random_state: 13\n",
      "Training accuracy: 0.8785359327217125\n",
      "Testing accuracy: 0.8341612533435231\n",
      "\n",
      "Random_state: 14\n",
      "Training accuracy: 0.880447247706422\n",
      "Testing accuracy: 0.8383645395491021\n",
      "\n",
      "Random_state: 15\n",
      "Training accuracy: 0.8812117737003058\n",
      "Testing accuracy: 0.8414214749713412\n",
      "\n",
      "Random_state: 16\n",
      "Training accuracy: 0.8792048929663608\n",
      "Testing accuracy: 0.8383645395491021\n",
      "\n",
      "Random_state: 17\n",
      "Training accuracy: 0.8798738532110092\n",
      "Testing accuracy: 0.853649216660298\n",
      "\n",
      "Random_state: 18\n",
      "Training accuracy: 0.8797782874617737\n",
      "Testing accuracy: 0.8402751241880015\n",
      "\n",
      "Random_state: 19\n",
      "Training accuracy: 0.8794915902140673\n",
      "Testing accuracy: 0.838746656476882\n",
      "\n",
      "Random_state: 20\n",
      "Training accuracy: 0.8784403669724771\n",
      "Testing accuracy: 0.8540313335880779\n",
      "\n",
      "Random_state: 21\n",
      "Training accuracy: 0.8751911314984709\n",
      "Testing accuracy: 0.8505922812380589\n",
      "\n",
      "Random_state: 22\n",
      "Training accuracy: 0.8759556574923547\n",
      "Testing accuracy: 0.8521207489491784\n",
      "\n",
      "Random_state: 23\n",
      "Training accuracy: 0.8811162079510704\n",
      "Testing accuracy: 0.8383645395491021\n",
      "\n",
      "Random_state: 24\n",
      "Training accuracy: 0.880638379204893\n",
      "Testing accuracy: 0.838746656476882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking various random states (20 gives the closest scores between the training and testing sets)\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X, y,\n",
    "                                                    random_state = i,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "    cvec3 = CountVectorizer(max_features=4000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "    # training dataframe\n",
    "    df3_train = pd.DataFrame(cvec3.fit_transform(X3_train).toarray(),\n",
    "                            columns=cvec3.get_feature_names())\n",
    "\n",
    "    # testing dataframe\n",
    "    df3_test = pd.DataFrame(cvec3.transform(X3_test).toarray(),\n",
    "                          columns=cvec3.get_feature_names())\n",
    "    \n",
    "    nb3 = MultinomialNB() \n",
    "    model3 = nb3.fit(df3_train, y3_train)\n",
    "    \n",
    "    print(f'Random_state: {i}')\n",
    "    print(f'Training accuracy: {nb3.score(df3_train, y3_train)}')\n",
    "    print(f'Testing accuracy: {nb3.score(df3_test, y3_test)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_state: 25\n",
      "Training accuracy: 0.878822629969419\n",
      "Testing accuracy: 0.8482995796713795\n",
      "\n",
      "Random_state: 26\n",
      "Training accuracy: 0.8793960244648318\n",
      "Testing accuracy: 0.834543370271303\n",
      "\n",
      "Random_state: 27\n",
      "Training accuracy: 0.8805428134556575\n",
      "Testing accuracy: 0.8314864348490638\n",
      "\n",
      "Random_state: 28\n",
      "Training accuracy: 0.8766246177370031\n",
      "Testing accuracy: 0.8593809705769966\n",
      "\n",
      "Random_state: 29\n",
      "Training accuracy: 0.8814984709480123\n",
      "Testing accuracy: 0.8391287734046619\n",
      "\n",
      "Random_state: 30\n",
      "Training accuracy: 0.8831230886850153\n",
      "Testing accuracy: 0.8398930072602216\n",
      "\n",
      "Random_state: 31\n",
      "Training accuracy: 0.8800649847094801\n",
      "Testing accuracy: 0.8418035918991211\n",
      "\n",
      "Random_state: 32\n",
      "Training accuracy: 0.8783448012232415\n",
      "Testing accuracy: 0.8494459304547192\n",
      "\n",
      "Random_state: 33\n",
      "Training accuracy: 0.8771980122324159\n",
      "Testing accuracy: 0.8333970194879633\n",
      "\n",
      "Random_state: 34\n",
      "Training accuracy: 0.8812117737003058\n",
      "Testing accuracy: 0.8318685517768437\n",
      "\n",
      "Random_state: 35\n",
      "Training accuracy: 0.8778669724770642\n",
      "Testing accuracy: 0.8444784103935804\n",
      "\n",
      "Random_state: 36\n",
      "Training accuracy: 0.8803516819571865\n",
      "Testing accuracy: 0.8456247611769201\n",
      "\n",
      "Random_state: 37\n",
      "Training accuracy: 0.8816896024464832\n",
      "Testing accuracy: 0.8418035918991211\n",
      "\n",
      "Random_state: 38\n",
      "Training accuracy: 0.8771980122324159\n",
      "Testing accuracy: 0.8460068781047\n",
      "\n",
      "Random_state: 39\n",
      "Training accuracy: 0.8826452599388379\n",
      "Testing accuracy: 0.8337791364157432\n",
      "\n",
      "Random_state: 40\n",
      "Training accuracy: 0.8807339449541285\n",
      "Testing accuracy: 0.8257546809323653\n",
      "\n",
      "Random_state: 41\n",
      "Training accuracy: 0.8799694189602446\n",
      "Testing accuracy: 0.8410393580435613\n",
      "\n",
      "Random_state: 42\n",
      "Training accuracy: 0.876815749235474\n",
      "Testing accuracy: 0.8433320596102407\n",
      "\n",
      "Random_state: 43\n",
      "Training accuracy: 0.8803516819571865\n",
      "Testing accuracy: 0.8437141765380206\n",
      "\n",
      "Random_state: 44\n",
      "Training accuracy: 0.878631498470948\n",
      "Testing accuracy: 0.8391287734046619\n",
      "\n",
      "Random_state: 45\n",
      "Training accuracy: 0.8798738532110092\n",
      "Testing accuracy: 0.8437141765380206\n",
      "\n",
      "Random_state: 46\n",
      "Training accuracy: 0.8792048929663608\n",
      "Testing accuracy: 0.8437141765380206\n",
      "\n",
      "Random_state: 47\n",
      "Training accuracy: 0.8781536697247706\n",
      "Testing accuracy: 0.8376003056935423\n",
      "\n",
      "Random_state: 48\n",
      "Training accuracy: 0.8800649847094801\n",
      "Testing accuracy: 0.8383645395491021\n",
      "\n",
      "Random_state: 49\n",
      "Training accuracy: 0.8812117737003058\n",
      "Testing accuracy: 0.8314864348490638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking various random states (28 gives the closest scores between the training and testing sets)\n",
    "\n",
    "for i in range(25, 50):\n",
    "\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X, y,\n",
    "                                                    random_state = i,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "    cvec3 = CountVectorizer(max_features=4000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "    # training dataframe\n",
    "    df3_train = pd.DataFrame(cvec3.fit_transform(X3_train).toarray(),\n",
    "                            columns=cvec3.get_feature_names())\n",
    "\n",
    "    # testing dataframe\n",
    "    df3_test = pd.DataFrame(cvec3.transform(X3_test).toarray(),\n",
    "                          columns=cvec3.get_feature_names())\n",
    "    \n",
    "    nb3 = MultinomialNB() \n",
    "    model3 = nb3.fit(df3_train, y3_train)\n",
    "    \n",
    "    print(f'Random_state: {i}')\n",
    "    print(f'Training accuracy: {nb3.score(df3_train, y3_train)}')\n",
    "    print(f'Testing accuracy: {nb3.score(df3_test, y3_test)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 out of 1000\n",
      "\n",
      "Random_state: 2\n",
      "Training accuracy: 0.8791093272171254\n",
      "Testing accuracy: 0.8528849828047382\n",
      "\n",
      "Random_state: 17\n",
      "Training accuracy: 0.8798738532110092\n",
      "Testing accuracy: 0.853649216660298\n",
      "\n",
      "Step 20 out of 1000\n",
      "\n",
      "Random_state: 20\n",
      "Training accuracy: 0.8784403669724771\n",
      "Testing accuracy: 0.8540313335880779\n",
      "\n",
      "Random_state: 21\n",
      "Training accuracy: 0.8751911314984709\n",
      "Testing accuracy: 0.8505922812380589\n",
      "\n",
      "Random_state: 22\n",
      "Training accuracy: 0.8759556574923547\n",
      "Testing accuracy: 0.8521207489491784\n",
      "\n",
      "Random_state: 28\n",
      "Training accuracy: 0.8766246177370031\n",
      "Testing accuracy: 0.8593809705769966\n",
      "\n",
      "Step 40 out of 1000\n",
      "\n",
      "Random_state: 53\n",
      "Training accuracy: 0.8778669724770642\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Step 60 out of 1000\n",
      "\n",
      "Step 80 out of 1000\n",
      "\n",
      "Random_state: 85\n",
      "Training accuracy: 0.8779625382262997\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 96\n",
      "Training accuracy: 0.8773891437308868\n",
      "Testing accuracy: 0.8517386320213985\n",
      "\n",
      "Step 100 out of 1000\n",
      "\n",
      "Step 120 out of 1000\n",
      "\n",
      "Random_state: 124\n",
      "Training accuracy: 0.8771024464831805\n",
      "Testing accuracy: 0.8567061520825373\n",
      "\n",
      "Step 140 out of 1000\n",
      "\n",
      "Step 160 out of 1000\n",
      "\n",
      "Step 180 out of 1000\n",
      "\n",
      "Random_state: 183\n",
      "Training accuracy: 0.8763379204892966\n",
      "Testing accuracy: 0.8505922812380589\n",
      "\n",
      "Random_state: 186\n",
      "Training accuracy: 0.8772935779816514\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Random_state: 194\n",
      "Training accuracy: 0.8795871559633027\n",
      "Testing accuracy: 0.8555598012991975\n",
      "\n",
      "Step 200 out of 1000\n",
      "\n",
      "Random_state: 202\n",
      "Training accuracy: 0.8757645259938838\n",
      "Testing accuracy: 0.853649216660298\n",
      "\n",
      "Random_state: 219\n",
      "Training accuracy: 0.8771980122324159\n",
      "Testing accuracy: 0.8540313335880779\n",
      "\n",
      "Step 220 out of 1000\n",
      "\n",
      "Random_state: 220\n",
      "Training accuracy: 0.8793004587155964\n",
      "Testing accuracy: 0.8517386320213985\n",
      "\n",
      "Random_state: 226\n",
      "Training accuracy: 0.8803516819571865\n",
      "Testing accuracy: 0.8532670997325181\n",
      "\n",
      "Step 240 out of 1000\n",
      "\n",
      "Random_state: 250\n",
      "Training accuracy: 0.8779625382262997\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Random_state: 256\n",
      "Training accuracy: 0.8773891437308868\n",
      "Testing accuracy: 0.8517386320213985\n",
      "\n",
      "Step 260 out of 1000\n",
      "\n",
      "Random_state: 261\n",
      "Training accuracy: 0.880638379204893\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 265\n",
      "Training accuracy: 0.8777714067278287\n",
      "Testing accuracy: 0.8517386320213985\n",
      "\n",
      "Step 280 out of 1000\n",
      "\n",
      "Step 300 out of 1000\n",
      "\n",
      "Random_state: 302\n",
      "Training accuracy: 0.8787270642201835\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Step 320 out of 1000\n",
      "\n",
      "Random_state: 322\n",
      "Training accuracy: 0.8766246177370031\n",
      "Testing accuracy: 0.8544134505158578\n",
      "\n",
      "Step 340 out of 1000\n",
      "\n",
      "Random_state: 347\n",
      "Training accuracy: 0.8773891437308868\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Step 360 out of 1000\n",
      "\n",
      "Random_state: 368\n",
      "Training accuracy: 0.8790137614678899\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Step 380 out of 1000\n",
      "\n",
      "Step 400 out of 1000\n",
      "\n",
      "Random_state: 407\n",
      "Training accuracy: 0.8766246177370031\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 417\n",
      "Training accuracy: 0.8759556574923547\n",
      "Testing accuracy: 0.8567061520825373\n",
      "\n",
      "Random_state: 418\n",
      "Training accuracy: 0.8776758409785933\n",
      "Testing accuracy: 0.8540313335880779\n",
      "\n",
      "Step 420 out of 1000\n",
      "\n",
      "Random_state: 422\n",
      "Training accuracy: 0.8759556574923547\n",
      "Testing accuracy: 0.8528849828047382\n",
      "\n",
      "Step 440 out of 1000\n",
      "\n",
      "Step 460 out of 1000\n",
      "\n",
      "Step 480 out of 1000\n",
      "\n",
      "Random_state: 494\n",
      "Training accuracy: 0.8765290519877675\n",
      "Testing accuracy: 0.8525028658769583\n",
      "\n",
      "Random_state: 497\n",
      "Training accuracy: 0.8776758409785933\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Step 500 out of 1000\n",
      "\n",
      "Random_state: 509\n",
      "Training accuracy: 0.8763379204892966\n",
      "Testing accuracy: 0.8589988536492167\n",
      "\n",
      "Random_state: 518\n",
      "Training accuracy: 0.8771024464831805\n",
      "Testing accuracy: 0.8544134505158578\n",
      "\n",
      "Random_state: 519\n",
      "Training accuracy: 0.8792048929663608\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Step 520 out of 1000\n",
      "\n",
      "Random_state: 524\n",
      "Training accuracy: 0.8801605504587156\n",
      "Testing accuracy: 0.8505922812380589\n",
      "\n",
      "Random_state: 531\n",
      "Training accuracy: 0.8802561162079511\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Step 540 out of 1000\n",
      "\n",
      "Step 560 out of 1000\n",
      "\n",
      "Random_state: 569\n",
      "Training accuracy: 0.8793004587155964\n",
      "Testing accuracy: 0.8525028658769583\n",
      "\n",
      "Step 580 out of 1000\n",
      "\n",
      "Random_state: 596\n",
      "Training accuracy: 0.8776758409785933\n",
      "Testing accuracy: 0.8551776843714176\n",
      "\n",
      "Step 600 out of 1000\n",
      "\n",
      "Step 620 out of 1000\n",
      "\n",
      "Random_state: 621\n",
      "Training accuracy: 0.8779625382262997\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 623\n",
      "Training accuracy: 0.877006880733945\n",
      "Testing accuracy: 0.8525028658769583\n",
      "\n",
      "Random_state: 634\n",
      "Training accuracy: 0.8776758409785933\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Step 640 out of 1000\n",
      "\n",
      "Random_state: 656\n",
      "Training accuracy: 0.8775802752293578\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Step 660 out of 1000\n",
      "\n",
      "Step 680 out of 1000\n",
      "\n",
      "Random_state: 686\n",
      "Training accuracy: 0.8808295107033639\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 688\n",
      "Training accuracy: 0.8771980122324159\n",
      "Testing accuracy: 0.8570882690103172\n",
      "\n",
      "Step 700 out of 1000\n",
      "\n",
      "Step 720 out of 1000\n",
      "\n",
      "Random_state: 723\n",
      "Training accuracy: 0.8781536697247706\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 735\n",
      "Training accuracy: 0.8769113149847095\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Random_state: 738\n",
      "Training accuracy: 0.8797782874617737\n",
      "Testing accuracy: 0.8528849828047382\n",
      "\n",
      "Step 740 out of 1000\n",
      "\n",
      "Step 760 out of 1000\n",
      "\n",
      "Step 780 out of 1000\n",
      "\n",
      "Random_state: 787\n",
      "Training accuracy: 0.8771980122324159\n",
      "Testing accuracy: 0.8563240351547573\n",
      "\n",
      "Random_state: 788\n",
      "Training accuracy: 0.8812117737003058\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Random_state: 796\n",
      "Training accuracy: 0.8764334862385321\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Step 800 out of 1000\n",
      "\n",
      "Random_state: 809\n",
      "Training accuracy: 0.8759556574923547\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Random_state: 819\n",
      "Training accuracy: 0.8766246177370031\n",
      "Testing accuracy: 0.8582346197936569\n",
      "\n",
      "Step 820 out of 1000\n",
      "\n",
      "Random_state: 826\n",
      "Training accuracy: 0.877006880733945\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 835\n",
      "Training accuracy: 0.8761467889908257\n",
      "Testing accuracy: 0.8505922812380589\n",
      "\n",
      "Step 840 out of 1000\n",
      "\n",
      "Step 860 out of 1000\n",
      "\n",
      "Random_state: 860\n",
      "Training accuracy: 0.8802561162079511\n",
      "Testing accuracy: 0.8540313335880779\n",
      "\n",
      "Random_state: 867\n",
      "Training accuracy: 0.8801605504587156\n",
      "Testing accuracy: 0.850210164310279\n",
      "\n",
      "Step 880 out of 1000\n",
      "\n",
      "Random_state: 882\n",
      "Training accuracy: 0.8765290519877675\n",
      "Testing accuracy: 0.8547955674436377\n",
      "\n",
      "Random_state: 886\n",
      "Training accuracy: 0.8763379204892966\n",
      "Testing accuracy: 0.8513565150936186\n",
      "\n",
      "Random_state: 890\n",
      "Training accuracy: 0.8780581039755352\n",
      "Testing accuracy: 0.8551776843714176\n",
      "\n",
      "Step 900 out of 1000\n",
      "\n",
      "Step 920 out of 1000\n",
      "\n",
      "Step 940 out of 1000\n",
      "\n",
      "Random_state: 948\n",
      "Training accuracy: 0.8772935779816514\n",
      "Testing accuracy: 0.8509743981658388\n",
      "\n",
      "Random_state: 949\n",
      "Training accuracy: 0.8763379204892966\n",
      "Testing accuracy: 0.8586167367214368\n",
      "\n",
      "Step 960 out of 1000\n",
      "\n",
      "Random_state: 974\n",
      "Training accuracy: 0.8794915902140673\n",
      "Testing accuracy: 0.8505922812380589\n",
      "\n",
      "Step 980 out of 1000\n",
      "\n",
      "Random_state: 994\n",
      "Training accuracy: 0.8774847094801224\n",
      "Testing accuracy: 0.8570882690103172\n",
      "\n",
      "Random_state: 995\n",
      "Training accuracy: 0.8776758409785933\n",
      "Testing accuracy: 0.8559419182269774\n",
      "\n",
      "time: 1482.008 seconds\n"
     ]
    }
   ],
   "source": [
    "# checking various random states (28 gives the closest scores between the training and testing sets)\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    if i % 20 == 0:\n",
    "        print(f'Step {i} out of {len(range(0, 1000))}')\n",
    "        print()\n",
    "    \n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X, y,\n",
    "                                                    random_state = i,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "    cvec3 = CountVectorizer(max_features=4000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "    # training dataframe\n",
    "    df3_train = pd.DataFrame(cvec3.fit_transform(X3_train).toarray(),\n",
    "                            columns=cvec3.get_feature_names())\n",
    "\n",
    "    # testing dataframe\n",
    "    df3_test = pd.DataFrame(cvec3.transform(X3_test).toarray(),\n",
    "                          columns=cvec3.get_feature_names())\n",
    "    \n",
    "    nb3 = MultinomialNB() \n",
    "    model3 = nb3.fit(df3_train, y3_train)\n",
    "    \n",
    "    if nb3.score(df3_test, y3_test) > 0.85:\n",
    "        \n",
    "        print(f'Random_state: {i}')\n",
    "        print(f'Training accuracy: {nb3.score(df3_train, y3_train)}')\n",
    "        print(f'Testing accuracy: {nb3.score(df3_test, y3_test)}')\n",
    "        print()\n",
    "    \n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)  \n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/blakewallace/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7799120795107034\n",
      "{'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'learning_rate': 1.0, 'n_estimators': 5}\n",
      "The training score: 0.9765863914373089\n",
      "The testing score: 0.7905999235766145\n",
      "Accuracy score 0.7905999235766145  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1036                 273\n",
      "Actually_Positive                 275                1033 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1309\n",
      "           1       0.79      0.79      0.79      1308\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2617\n",
      "   macro avg       0.79      0.79      0.79      2617\n",
      "weighted avg       0.79      0.79      0.79      2617\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "True Negatives: 715\n",
      "False Positives: 594\n",
      "False Negatives: 733\n",
      "True Positives: 575\n",
      "time: 590.091 seconds\n",
      "time: 9 minutes, 50.091 seconds\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost to try and eliminate some of the bias within the Bayes model\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 26,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=4000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "\n",
    "ada = AdaBoostClassifier()  # we are not limited to only decision trees with this model 'base_estimator' max_depth=1 is high bias\n",
    "                            # we are not limited to the number of \n",
    "\n",
    "ada_params = {\n",
    "    'base_estimator': [MultinomialNB(), RandomForestClassifier(), None],\n",
    "    'n_estimators'  : [5],\n",
    "    'learning_rate' : [1.0]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(ada, \n",
    "                  param_grid=ada_params, \n",
    "                  verbose = 1,\n",
    "                  cv=5)\n",
    "gs.fit(df_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "print(f'The training score: {gs.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs.score(df_test, y_test)}')\n",
    "\n",
    "preds = gs.predict(df_test)\n",
    "\n",
    "metrics(y_test, preds)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6beb8383e853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=4000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB()],\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10464, 4000)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000 pieces</th>\n",
       "      <th>10</th>\n",
       "      <th>10 year</th>\n",
       "      <th>10 year old</th>\n",
       "      <th>10 years</th>\n",
       "      <th>100</th>\n",
       "      <th>100 000</th>\n",
       "      <th>1000</th>\n",
       "      <th>105</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>12 year</th>\n",
       "      <th>12 year old</th>\n",
       "      <th>120</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>16</th>\n",
       "      <th>16 years</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>1967</th>\n",
       "      <th>1980s</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1996</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>20 year</th>\n",
       "      <th>20 years</th>\n",
       "      <th>200</th>\n",
       "      <th>2000</th>\n",
       "      <th>2003</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2018 lego</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>20th</th>\n",
       "      <th>20th anniversary</th>\n",
       "      <th>20th anniversary sets</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>250</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>2nd</th>\n",
       "      <th>30</th>\n",
       "      <th>300</th>\n",
       "      <th>32</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>3d</th>\n",
       "      <th>40</th>\n",
       "      <th>400</th>\n",
       "      <th>41</th>\n",
       "      <th>45</th>\n",
       "      <th>4th</th>\n",
       "      <th>50</th>\n",
       "      <th>5000</th>\n",
       "      <th>501st</th>\n",
       "      <th>55</th>\n",
       "      <th>59</th>\n",
       "      <th>5th</th>\n",
       "      <th>60</th>\n",
       "      <th>64</th>\n",
       "      <th>66</th>\n",
       "      <th>70</th>\n",
       "      <th>75</th>\n",
       "      <th>75105</th>\n",
       "      <th>75131</th>\n",
       "      <th>75155</th>\n",
       "      <th>75179</th>\n",
       "      <th>75181</th>\n",
       "      <th>75189</th>\n",
       "      <th>75190</th>\n",
       "      <th>75191</th>\n",
       "      <th>75192</th>\n",
       "      <th>75211</th>\n",
       "      <th>75222</th>\n",
       "      <th>76</th>\n",
       "      <th>80</th>\n",
       "      <th>800</th>\n",
       "      <th>80s</th>\n",
       "      <th>90</th>\n",
       "      <th>90s</th>\n",
       "      <th>90s kids</th>\n",
       "      <th>911</th>\n",
       "      <th>99</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accurate</th>\n",
       "      <th>accused</th>\n",
       "      <th>achieved</th>\n",
       "      <th>achievement</th>\n",
       "      <th>act</th>\n",
       "      <th>act scene</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>ad</th>\n",
       "      <th>adam</th>\n",
       "      <th>adam west</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>addiction</th>\n",
       "      <th>adding</th>\n",
       "      <th>addition</th>\n",
       "      <th>addition collection</th>\n",
       "      <th>additions</th>\n",
       "      <th>admiral</th>\n",
       "      <th>adorable</th>\n",
       "      <th>adult</th>\n",
       "      <th>advanced</th>\n",
       "      <th>advent</th>\n",
       "      <th>advent calendar</th>\n",
       "      <th>adventures</th>\n",
       "      <th>advertising</th>\n",
       "      <th>advice</th>\n",
       "      <th>afford</th>\n",
       "      <th>afraid</th>\n",
       "      <th>african</th>\n",
       "      <th>age</th>\n",
       "      <th>ages</th>\n",
       "      <th>ago</th>\n",
       "      <th>agree</th>\n",
       "      <th>ahch</th>\n",
       "      <th>ahead</th>\n",
       "      <th>aid</th>\n",
       "      <th>ain</th>\n",
       "      <th>air</th>\n",
       "      <th>airlines</th>\n",
       "      <th>airplane</th>\n",
       "      <th>airport</th>\n",
       "      <th>al</th>\n",
       "      <th>alarm</th>\n",
       "      <th>alaska</th>\n",
       "      <th>album</th>\n",
       "      <th>album comments</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>alderaan</th>\n",
       "      <th>alderaan playset</th>\n",
       "      <th>ali</th>\n",
       "      <th>alien</th>\n",
       "      <th>alive</th>\n",
       "      <th>alley</th>\n",
       "      <th>alliance</th>\n",
       "      <th>allow</th>\n",
       "      <th>allowance</th>\n",
       "      <th>allowed</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alright</th>\n",
       "      <th>alternate</th>\n",
       "      <th>alternate build</th>\n",
       "      <th>alternative</th>\n",
       "      <th>ama</th>\n",
       "      <th>amazing</th>\n",
       "      <th>amazing lego</th>\n",
       "      <th>amazon</th>\n",
       "      <th>america</th>\n",
       "      <th>america 2016</th>\n",
       "      <th>american</th>\n",
       "      <th>americans</th>\n",
       "      <th>amigos</th>\n",
       "      <th>anakin</th>\n",
       "      <th>ancient</th>\n",
       "      <th>android</th>\n",
       "      <th>angeles</th>\n",
       "      <th>anger</th>\n",
       "      <th>angle</th>\n",
       "      <th>angry</th>\n",
       "      <th>animal</th>\n",
       "      <th>animals</th>\n",
       "      <th>animated</th>\n",
       "      <th>animation</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>anniversary sets</th>\n",
       "      <th>anniversary slave</th>\n",
       "      <th>announce</th>\n",
       "      <th>announced</th>\n",
       "      <th>announcement</th>\n",
       "      <th>announces</th>\n",
       "      <th>anon</th>\n",
       "      <th>answer</th>\n",
       "      <th>anti</th>\n",
       "      <th>ants</th>\n",
       "      <th>anybody</th>\n",
       "      <th>anybody know</th>\n",
       "      <th>anybody remember</th>\n",
       "      <th>anymore</th>\n",
       "      <th>anyways</th>\n",
       "      <th>ap</th>\n",
       "      <th>apart</th>\n",
       "      <th>apartment</th>\n",
       "      <th>apocalypse</th>\n",
       "      <th>apocalyptic</th>\n",
       "      <th>apollo</th>\n",
       "      <th>apologize</th>\n",
       "      <th>app</th>\n",
       "      <th>apparently</th>\n",
       "      <th>appeal</th>\n",
       "      <th>appear</th>\n",
       "      <th>apple</th>\n",
       "      <th>appreciate</th>\n",
       "      <th>appreciated</th>\n",
       "      <th>approaches</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>apr</th>\n",
       "      <th>apr 2019</th>\n",
       "      <th>april</th>\n",
       "      <th>april 2019</th>\n",
       "      <th>april fools</th>\n",
       "      <th>aquarium</th>\n",
       "      <th>arab</th>\n",
       "      <th>arabia</th>\n",
       "      <th>arc</th>\n",
       "      <th>arc 170</th>\n",
       "      <th>arcade</th>\n",
       "      <th>arcade machines</th>\n",
       "      <th>architect</th>\n",
       "      <th>architecture</th>\n",
       "      <th>area</th>\n",
       "      <th>aren</th>\n",
       "      <th>arizona</th>\n",
       "      <th>arm</th>\n",
       "      <th>armed</th>\n",
       "      <th>armor</th>\n",
       "      <th>arms</th>\n",
       "      <th>army</th>\n",
       "      <th>arrest</th>\n",
       "      <th>arrested</th>\n",
       "      <th>arrived</th>\n",
       "      <th>arrived today</th>\n",
       "      <th>art</th>\n",
       "      <th>article</th>\n",
       "      <th>artist</th>\n",
       "      <th>ask</th>\n",
       "      <th>asked</th>\n",
       "      <th>asking</th>\n",
       "      <th>asks</th>\n",
       "      <th>asleep</th>\n",
       "      <th>ass</th>\n",
       "      <th>assault</th>\n",
       "      <th>asshole</th>\n",
       "      <th>astromech</th>\n",
       "      <th>attack</th>\n",
       "      <th>attempt</th>\n",
       "      <th>attention</th>\n",
       "      <th>august</th>\n",
       "      <th>aunt</th>\n",
       "      <th>aurora</th>\n",
       "      <th>austin</th>\n",
       "      <th>australia</th>\n",
       "      <th>australian</th>\n",
       "      <th>autism</th>\n",
       "      <th>automatic</th>\n",
       "      <th>autumn</th>\n",
       "      <th>availability</th>\n",
       "      <th>available</th>\n",
       "      <th>avengers</th>\n",
       "      <th>avengers endgame</th>\n",
       "      <th>avengers infinity</th>\n",
       "      <th>avengers infinity war</th>\n",
       "      <th>average</th>\n",
       "      <th>awakens</th>\n",
       "      <th>awakens review</th>\n",
       "      <th>award</th>\n",
       "      <th>awards</th>\n",
       "      <th>awareness</th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awesome lego</th>\n",
       "      <th>awhile</th>\n",
       "      <th>aww</th>\n",
       "      <th>babies</th>\n",
       "      <th>baby</th>\n",
       "      <th>background</th>\n",
       "      <th>backlog</th>\n",
       "      <th>backwards</th>\n",
       "      <th>backyard</th>\n",
       "      <th>bacon</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad ass</th>\n",
       "      <th>bad boy</th>\n",
       "      <th>bad quality</th>\n",
       "      <th>badass</th>\n",
       "      <th>bag</th>\n",
       "      <th>bags</th>\n",
       "      <th>bakery</th>\n",
       "      <th>balcony</th>\n",
       "      <th>ball</th>\n",
       "      <th>balls</th>\n",
       "      <th>ban</th>\n",
       "      <th>banana</th>\n",
       "      <th>banana scale</th>\n",
       "      <th>band</th>\n",
       "      <th>bang</th>\n",
       "      <th>bank</th>\n",
       "      <th>banksy</th>\n",
       "      <th>banned</th>\n",
       "      <th>bans</th>\n",
       "      <th>bar</th>\n",
       "      <th>barbie</th>\n",
       "      <th>barc</th>\n",
       "      <th>barc speeder</th>\n",
       "      <th>barcelona</th>\n",
       "      <th>bardstown</th>\n",
       "      <th>bardstown ky</th>\n",
       "      <th>barnes</th>\n",
       "      <th>barry</th>\n",
       "      <th>bars</th>\n",
       "      <th>base</th>\n",
       "      <th>base moc</th>\n",
       "      <th>baseball</th>\n",
       "      <th>based</th>\n",
       "      <th>basement</th>\n",
       "      <th>basically</th>\n",
       "      <th>basketball</th>\n",
       "      <th>bass</th>\n",
       "      <th>bat</th>\n",
       "      <th>batcave</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>batman</th>\n",
       "      <th>batman movie</th>\n",
       "      <th>batmobile</th>\n",
       "      <th>battle</th>\n",
       "      <th>battle droid</th>\n",
       "      <th>battle pack</th>\n",
       "      <th>battle packs</th>\n",
       "      <th>battlefront</th>\n",
       "      <th>battlefront moc</th>\n",
       "      <th>battlepack</th>\n",
       "      <th>bay</th>\n",
       "      <th>bb</th>\n",
       "      <th>beach</th>\n",
       "      <th>bean</th>\n",
       "      <th>bear</th>\n",
       "      <th>beard</th>\n",
       "      <th>beast</th>\n",
       "      <th>beatles</th>\n",
       "      <th>beats</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>beauty</th>\n",
       "      <th>bed</th>\n",
       "      <th>beer</th>\n",
       "      <th>beetle</th>\n",
       "      <th>begin</th>\n",
       "      <th>beginning</th>\n",
       "      <th>begins</th>\n",
       "      <th>behold</th>\n",
       "      <th>believe</th>\n",
       "      <th>bell</th>\n",
       "      <th>belonged</th>\n",
       "      <th>belongs</th>\n",
       "      <th>ben</th>\n",
       "      <th>bernie</th>\n",
       "      <th>bernie sanders</th>\n",
       "      <th>bespin</th>\n",
       "      <th>best</th>\n",
       "      <th>best friend</th>\n",
       "      <th>best friends</th>\n",
       "      <th>best lego</th>\n",
       "      <th>best picture</th>\n",
       "      <th>best place</th>\n",
       "      <th>best thing</th>\n",
       "      <th>best war</th>\n",
       "      <th>best war stream</th>\n",
       "      <th>best way</th>\n",
       "      <th>betrayal</th>\n",
       "      <th>betrayal cloud</th>\n",
       "      <th>betrayal cloud city</th>\n",
       "      <th>better</th>\n",
       "      <th>beware</th>\n",
       "      <th>bf</th>\n",
       "      <th>bible</th>\n",
       "      <th>bieber</th>\n",
       "      <th>big</th>\n",
       "      <th>big fan</th>\n",
       "      <th>big lego</th>\n",
       "      <th>bigger</th>\n",
       "      <th>biggest</th>\n",
       "      <th>bike</th>\n",
       "      <th>bike moc</th>\n",
       "      <th>bikes</th>\n",
       "      <th>biking</th>\n",
       "      <th>billion</th>\n",
       "      <th>billund</th>\n",
       "      <th>bin</th>\n",
       "      <th>bird</th>\n",
       "      <th>birds</th>\n",
       "      <th>birth</th>\n",
       "      <th>birthday</th>\n",
       "      <th>bit</th>\n",
       "      <th>bitch</th>\n",
       "      <th>black</th>\n",
       "      <th>black friday</th>\n",
       "      <th>black lion</th>\n",
       "      <th>blacktron</th>\n",
       "      <th>blade</th>\n",
       "      <th>blanket</th>\n",
       "      <th>bleeding</th>\n",
       "      <th>blind</th>\n",
       "      <th>block</th>\n",
       "      <th>blocks</th>\n",
       "      <th>blog</th>\n",
       "      <th>blood</th>\n",
       "      <th>blow</th>\n",
       "      <th>blue</th>\n",
       "      <th>board</th>\n",
       "      <th>boat</th>\n",
       "      <th>bob</th>\n",
       "      <th>boba</th>\n",
       "      <th>boba fett</th>\n",
       "      <th>boca</th>\n",
       "      <th>body</th>\n",
       "      <th>boi</th>\n",
       "      <th>bold</th>\n",
       "      <th>bomber</th>\n",
       "      <th>bonus</th>\n",
       "      <th>boobs</th>\n",
       "      <th>book</th>\n",
       "      <th>booked</th>\n",
       "      <th>books</th>\n",
       "      <th>boom</th>\n",
       "      <th>boost</th>\n",
       "      <th>boots</th>\n",
       "      <th>borderlands</th>\n",
       "      <th>borderlands box</th>\n",
       "      <th>borderlands box art</th>\n",
       "      <th>bored</th>\n",
       "      <th>boring</th>\n",
       "      <th>born</th>\n",
       "      <th>boss</th>\n",
       "      <th>boston</th>\n",
       "      <th>bot</th>\n",
       "      <th>bothered</th>\n",
       "      <th>bots</th>\n",
       "      <th>bottle</th>\n",
       "      <th>bought</th>\n",
       "      <th>bought new</th>\n",
       "      <th>bought set</th>\n",
       "      <th>bounty</th>\n",
       "      <th>bounty hunter</th>\n",
       "      <th>bounty hunters</th>\n",
       "      <th>bowl</th>\n",
       "      <th>box</th>\n",
       "      <th>boxes</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyfriend</th>\n",
       "      <th>boys</th>\n",
       "      <th>brain</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand new</th>\n",
       "      <th>brazil</th>\n",
       "      <th>bread</th>\n",
       "      <th>break</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>breaking</th>\n",
       "      <th>breaking bad</th>\n",
       "      <th>brick</th>\n",
       "      <th>brickfilm</th>\n",
       "      <th>brickhead</th>\n",
       "      <th>brickheadz</th>\n",
       "      <th>bricklink</th>\n",
       "      <th>bricks</th>\n",
       "      <th>bricks lego</th>\n",
       "      <th>brickvault</th>\n",
       "      <th>bridge</th>\n",
       "      <th>bring</th>\n",
       "      <th>brings</th>\n",
       "      <th>british</th>\n",
       "      <th>bro</th>\n",
       "      <th>...</th>\n",
       "      <th>think ve</th>\n",
       "      <th>thinking</th>\n",
       "      <th>thinks</th>\n",
       "      <th>tho</th>\n",
       "      <th>thomas</th>\n",
       "      <th>thor</th>\n",
       "      <th>thorin</th>\n",
       "      <th>thought</th>\n",
       "      <th>thought cool</th>\n",
       "      <th>thought guys</th>\n",
       "      <th>thought like</th>\n",
       "      <th>thought post</th>\n",
       "      <th>thought share</th>\n",
       "      <th>thoughts</th>\n",
       "      <th>thoughts lego</th>\n",
       "      <th>thousand</th>\n",
       "      <th>thousands</th>\n",
       "      <th>thrawn</th>\n",
       "      <th>thread</th>\n",
       "      <th>threw</th>\n",
       "      <th>thrift</th>\n",
       "      <th>thrift store</th>\n",
       "      <th>thriller</th>\n",
       "      <th>throne</th>\n",
       "      <th>throne room</th>\n",
       "      <th>throw</th>\n",
       "      <th>throwing</th>\n",
       "      <th>tie</th>\n",
       "      <th>tie fighter</th>\n",
       "      <th>tie fighters</th>\n",
       "      <th>tie interceptor</th>\n",
       "      <th>ties</th>\n",
       "      <th>tifu</th>\n",
       "      <th>til</th>\n",
       "      <th>tiles</th>\n",
       "      <th>till</th>\n",
       "      <th>tim</th>\n",
       "      <th>tim goddard</th>\n",
       "      <th>time</th>\n",
       "      <th>time lapse</th>\n",
       "      <th>time lapse build</th>\n",
       "      <th>time picture</th>\n",
       "      <th>time posting</th>\n",
       "      <th>timelapse</th>\n",
       "      <th>timelapse build</th>\n",
       "      <th>times</th>\n",
       "      <th>tiny</th>\n",
       "      <th>tip</th>\n",
       "      <th>tips</th>\n",
       "      <th>tired</th>\n",
       "      <th>titanfall</th>\n",
       "      <th>titanic</th>\n",
       "      <th>title</th>\n",
       "      <th>tlj</th>\n",
       "      <th>today</th>\n",
       "      <th>today haul</th>\n",
       "      <th>todays</th>\n",
       "      <th>toilet</th>\n",
       "      <th>tokyo</th>\n",
       "      <th>told</th>\n",
       "      <th>tom</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>ton</th>\n",
       "      <th>tonight</th>\n",
       "      <th>tony</th>\n",
       "      <th>took</th>\n",
       "      <th>took ago</th>\n",
       "      <th>took days</th>\n",
       "      <th>took lot</th>\n",
       "      <th>took lot time</th>\n",
       "      <th>took phone</th>\n",
       "      <th>took photo</th>\n",
       "      <th>took picture</th>\n",
       "      <th>tool</th>\n",
       "      <th>tooth</th>\n",
       "      <th>torn</th>\n",
       "      <th>toronto</th>\n",
       "      <th>torso</th>\n",
       "      <th>total</th>\n",
       "      <th>totally</th>\n",
       "      <th>totally worth</th>\n",
       "      <th>touch</th>\n",
       "      <th>tough</th>\n",
       "      <th>tour</th>\n",
       "      <th>tournament</th>\n",
       "      <th>tower</th>\n",
       "      <th>towers</th>\n",
       "      <th>town</th>\n",
       "      <th>toy</th>\n",
       "      <th>toy store</th>\n",
       "      <th>toys</th>\n",
       "      <th>track</th>\n",
       "      <th>tractor</th>\n",
       "      <th>trade</th>\n",
       "      <th>traded</th>\n",
       "      <th>trading</th>\n",
       "      <th>traditional</th>\n",
       "      <th>traffic</th>\n",
       "      <th>trailer</th>\n",
       "      <th>train</th>\n",
       "      <th>training</th>\n",
       "      <th>trandish</th>\n",
       "      <th>trans</th>\n",
       "      <th>transformation</th>\n",
       "      <th>transformers</th>\n",
       "      <th>transforming</th>\n",
       "      <th>transport</th>\n",
       "      <th>trap</th>\n",
       "      <th>trapped</th>\n",
       "      <th>trash</th>\n",
       "      <th>travel</th>\n",
       "      <th>treat</th>\n",
       "      <th>treated</th>\n",
       "      <th>tree</th>\n",
       "      <th>tree planting</th>\n",
       "      <th>trees</th>\n",
       "      <th>trench</th>\n",
       "      <th>trench run</th>\n",
       "      <th>trend</th>\n",
       "      <th>tribute</th>\n",
       "      <th>tried</th>\n",
       "      <th>tried make</th>\n",
       "      <th>tries</th>\n",
       "      <th>trigger</th>\n",
       "      <th>trilogy</th>\n",
       "      <th>trip</th>\n",
       "      <th>triple</th>\n",
       "      <th>tron</th>\n",
       "      <th>troop</th>\n",
       "      <th>troop transport</th>\n",
       "      <th>trooper</th>\n",
       "      <th>trooper battle</th>\n",
       "      <th>trooper battle pack</th>\n",
       "      <th>troopers</th>\n",
       "      <th>troopers meet</th>\n",
       "      <th>troops</th>\n",
       "      <th>trouble</th>\n",
       "      <th>troy</th>\n",
       "      <th>tru</th>\n",
       "      <th>truck</th>\n",
       "      <th>true</th>\n",
       "      <th>true love</th>\n",
       "      <th>true story</th>\n",
       "      <th>truly</th>\n",
       "      <th>trump</th>\n",
       "      <th>trunk</th>\n",
       "      <th>trust</th>\n",
       "      <th>truth</th>\n",
       "      <th>try</th>\n",
       "      <th>try make</th>\n",
       "      <th>trying</th>\n",
       "      <th>tsm</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>turkey</th>\n",
       "      <th>turn</th>\n",
       "      <th>turned</th>\n",
       "      <th>turning</th>\n",
       "      <th>turns</th>\n",
       "      <th>turret</th>\n",
       "      <th>turtle</th>\n",
       "      <th>tv</th>\n",
       "      <th>tweet</th>\n",
       "      <th>twitter</th>\n",
       "      <th>type</th>\n",
       "      <th>types</th>\n",
       "      <th>ucs</th>\n",
       "      <th>ucs falcon</th>\n",
       "      <th>ucs millenium</th>\n",
       "      <th>ucs millenium falcon</th>\n",
       "      <th>ucs millennium</th>\n",
       "      <th>ucs millennium falcon</th>\n",
       "      <th>ucs set</th>\n",
       "      <th>ucs sets</th>\n",
       "      <th>ucs slave</th>\n",
       "      <th>ucs wing</th>\n",
       "      <th>ugly</th>\n",
       "      <th>uk</th>\n",
       "      <th>ult</th>\n",
       "      <th>ultimate</th>\n",
       "      <th>ultimate collector</th>\n",
       "      <th>ultimate collector series</th>\n",
       "      <th>ultra</th>\n",
       "      <th>ultron</th>\n",
       "      <th>unboxing</th>\n",
       "      <th>uncle</th>\n",
       "      <th>understand</th>\n",
       "      <th>underwater</th>\n",
       "      <th>unfinished</th>\n",
       "      <th>unikitty</th>\n",
       "      <th>unique</th>\n",
       "      <th>unit</th>\n",
       "      <th>united</th>\n",
       "      <th>united states</th>\n",
       "      <th>universe</th>\n",
       "      <th>university</th>\n",
       "      <th>unknown</th>\n",
       "      <th>unless</th>\n",
       "      <th>unlimited</th>\n",
       "      <th>unlock</th>\n",
       "      <th>unlocked</th>\n",
       "      <th>unopened</th>\n",
       "      <th>unpopular</th>\n",
       "      <th>unpopular opinion</th>\n",
       "      <th>unsure</th>\n",
       "      <th>upcoming</th>\n",
       "      <th>update</th>\n",
       "      <th>updated</th>\n",
       "      <th>upgrade</th>\n",
       "      <th>upgraded</th>\n",
       "      <th>upper</th>\n",
       "      <th>upvote</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>usa</th>\n",
       "      <th>usd</th>\n",
       "      <th>use</th>\n",
       "      <th>used</th>\n",
       "      <th>useless</th>\n",
       "      <th>user</th>\n",
       "      <th>users</th>\n",
       "      <th>uses</th>\n",
       "      <th>using</th>\n",
       "      <th>usual</th>\n",
       "      <th>usually</th>\n",
       "      <th>utah</th>\n",
       "      <th>v2</th>\n",
       "      <th>vacation</th>\n",
       "      <th>vader</th>\n",
       "      <th>vader bust</th>\n",
       "      <th>vader castle</th>\n",
       "      <th>vaders</th>\n",
       "      <th>valentine</th>\n",
       "      <th>valentine day</th>\n",
       "      <th>valley</th>\n",
       "      <th>valuable</th>\n",
       "      <th>value</th>\n",
       "      <th>valve</th>\n",
       "      <th>van</th>\n",
       "      <th>vancouver</th>\n",
       "      <th>ve</th>\n",
       "      <th>ve bought</th>\n",
       "      <th>ve got</th>\n",
       "      <th>ve heard</th>\n",
       "      <th>ve just</th>\n",
       "      <th>ve seen</th>\n",
       "      <th>ve taken</th>\n",
       "      <th>ve working</th>\n",
       "      <th>vegas</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>vehicles</th>\n",
       "      <th>venator</th>\n",
       "      <th>venator moc</th>\n",
       "      <th>venom</th>\n",
       "      <th>version</th>\n",
       "      <th>vet</th>\n",
       "      <th>vhs</th>\n",
       "      <th>video</th>\n",
       "      <th>video game</th>\n",
       "      <th>video lego</th>\n",
       "      <th>videos</th>\n",
       "      <th>vietnam</th>\n",
       "      <th>view</th>\n",
       "      <th>views</th>\n",
       "      <th>village</th>\n",
       "      <th>vintage</th>\n",
       "      <th>violence</th>\n",
       "      <th>vip</th>\n",
       "      <th>vip points</th>\n",
       "      <th>virginia</th>\n",
       "      <th>virginia living</th>\n",
       "      <th>virginia living museum</th>\n",
       "      <th>virus</th>\n",
       "      <th>vision</th>\n",
       "      <th>visit</th>\n",
       "      <th>visited</th>\n",
       "      <th>visiting</th>\n",
       "      <th>voice</th>\n",
       "      <th>vol</th>\n",
       "      <th>voltron</th>\n",
       "      <th>volume</th>\n",
       "      <th>vonreg</th>\n",
       "      <th>vote</th>\n",
       "      <th>voted</th>\n",
       "      <th>voter</th>\n",
       "      <th>votes</th>\n",
       "      <th>voting</th>\n",
       "      <th>vs</th>\n",
       "      <th>vs new</th>\n",
       "      <th>vs tsm</th>\n",
       "      <th>vulture</th>\n",
       "      <th>wa</th>\n",
       "      <th>wait</th>\n",
       "      <th>wait build</th>\n",
       "      <th>waiting</th>\n",
       "      <th>waiting line</th>\n",
       "      <th>wake</th>\n",
       "      <th>wal</th>\n",
       "      <th>wal mart</th>\n",
       "      <th>walk</th>\n",
       "      <th>walked</th>\n",
       "      <th>walker</th>\n",
       "      <th>walkers</th>\n",
       "      <th>walking</th>\n",
       "      <th>walks</th>\n",
       "      <th>wall</th>\n",
       "      <th>wall trees</th>\n",
       "      <th>wallet</th>\n",
       "      <th>wallpaper</th>\n",
       "      <th>walls</th>\n",
       "      <th>walmart</th>\n",
       "      <th>wan</th>\n",
       "      <th>wan kenobi</th>\n",
       "      <th>wanna</th>\n",
       "      <th>want</th>\n",
       "      <th>want build</th>\n",
       "      <th>want make</th>\n",
       "      <th>wanted</th>\n",
       "      <th>wanted know</th>\n",
       "      <th>wanted share</th>\n",
       "      <th>wanting</th>\n",
       "      <th>wants</th>\n",
       "      <th>wants photo</th>\n",
       "      <th>war</th>\n",
       "      <th>war stream</th>\n",
       "      <th>war stream mega</th>\n",
       "      <th>ward</th>\n",
       "      <th>warfare</th>\n",
       "      <th>warning</th>\n",
       "      <th>warrior</th>\n",
       "      <th>wars</th>\n",
       "      <th>wars 2017</th>\n",
       "      <th>wars 20th</th>\n",
       "      <th>wars 20th anniversary</th>\n",
       "      <th>wars advent</th>\n",
       "      <th>wars advent calendar</th>\n",
       "      <th>wars best</th>\n",
       "      <th>wars best war</th>\n",
       "      <th>wars collection</th>\n",
       "      <th>wars complete</th>\n",
       "      <th>wars complete saga</th>\n",
       "      <th>wars darth</th>\n",
       "      <th>wars echo</th>\n",
       "      <th>wars echo squadron</th>\n",
       "      <th>wars episode</th>\n",
       "      <th>wars fans</th>\n",
       "      <th>wars force</th>\n",
       "      <th>wars force awakens</th>\n",
       "      <th>wars game</th>\n",
       "      <th>wars imperial</th>\n",
       "      <th>wars jedi</th>\n",
       "      <th>wars lego</th>\n",
       "      <th>wars lego collection</th>\n",
       "      <th>wars legos</th>\n",
       "      <th>wars rebels</th>\n",
       "      <th>wars resistance</th>\n",
       "      <th>wars set</th>\n",
       "      <th>wars sets</th>\n",
       "      <th>wars story</th>\n",
       "      <th>wars ucs</th>\n",
       "      <th>wars video</th>\n",
       "      <th>wash</th>\n",
       "      <th>washing</th>\n",
       "      <th>washington</th>\n",
       "      <th>wasn</th>\n",
       "      <th>watch</th>\n",
       "      <th>watched</th>\n",
       "      <th>watching</th>\n",
       "      <th>water</th>\n",
       "      <th>wave</th>\n",
       "      <th>waves</th>\n",
       "      <th>way</th>\n",
       "      <th>way home</th>\n",
       "      <th>wayne</th>\n",
       "      <th>wayne manor</th>\n",
       "      <th>ways</th>\n",
       "      <th>weapon</th>\n",
       "      <th>weapons</th>\n",
       "      <th>wear</th>\n",
       "      <th>wearing</th>\n",
       "      <th>weather</th>\n",
       "      <th>web</th>\n",
       "      <th>website</th>\n",
       "      <th>websites</th>\n",
       "      <th>wedding</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>week</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weeks</th>\n",
       "      <th>weeks ago</th>\n",
       "      <th>weight</th>\n",
       "      <th>weird</th>\n",
       "      <th>welcome</th>\n",
       "      <th>welp</th>\n",
       "      <th>went</th>\n",
       "      <th>werewolf</th>\n",
       "      <th>west</th>\n",
       "      <th>wet</th>\n",
       "      <th>whale</th>\n",
       "      <th>whales</th>\n",
       "      <th>wheel</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>wheels</th>\n",
       "      <th>whisky</th>\n",
       "      <th>whisky distillery</th>\n",
       "      <th>whisky distillery bardstown</th>\n",
       "      <th>white</th>\n",
       "      <th>white house</th>\n",
       "      <th>white whale</th>\n",
       "      <th>wide</th>\n",
       "      <th>wife</th>\n",
       "      <th>wife got</th>\n",
       "      <th>wifi</th>\n",
       "      <th>wild</th>\n",
       "      <th>willie</th>\n",
       "      <th>wily</th>\n",
       "      <th>win</th>\n",
       "      <th>wind</th>\n",
       "      <th>window</th>\n",
       "      <th>windows</th>\n",
       "      <th>wing</th>\n",
       "      <th>wing moc</th>\n",
       "      <th>wing starfighter</th>\n",
       "      <th>wings</th>\n",
       "      <th>wins</th>\n",
       "      <th>winter</th>\n",
       "      <th>wip</th>\n",
       "      <th>wish</th>\n",
       "      <th>wolves</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>women nasa</th>\n",
       "      <th>won</th>\n",
       "      <th>wonder</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>wondering</th>\n",
       "      <th>wood</th>\n",
       "      <th>wooden</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>work</th>\n",
       "      <th>work progress</th>\n",
       "      <th>worked</th>\n",
       "      <th>worker</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>working lego</th>\n",
       "      <th>works</th>\n",
       "      <th>world</th>\n",
       "      <th>world war</th>\n",
       "      <th>worlds</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>wtf</th>\n",
       "      <th>ww2</th>\n",
       "      <th>wwii</th>\n",
       "      <th>www</th>\n",
       "      <th>xbox</th>\n",
       "      <th>xd</th>\n",
       "      <th>xi</th>\n",
       "      <th>xmas</th>\n",
       "      <th>xpost</th>\n",
       "      <th>ya</th>\n",
       "      <th>yard</th>\n",
       "      <th>yard sale</th>\n",
       "      <th>yavin</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year old</th>\n",
       "      <th>year old boy</th>\n",
       "      <th>year old son</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>years later</th>\n",
       "      <th>years old</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoda</th>\n",
       "      <th>yoda hut</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube channel</th>\n",
       "      <th>yr</th>\n",
       "      <th>yr old</th>\n",
       "      <th>zelda</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  000 pieces  10  10 year  10 year old  10 years  100  100 000  \\\n",
       "0   0    0           0   0        0            0         0    0        0   \n",
       "1   0    0           0   0        0            0         0    0        0   \n",
       "2   0    0           0   0        0            0         0    0        0   \n",
       "3   0    0           0   0        0            0         0    0        0   \n",
       "4   0    0           0   0        0            0         0    0        0   \n",
       "\n",
       "   1000  105  11  12  12 year  12 year old  120  13  14  15  150  16  \\\n",
       "0     0    0   0   0        0            0    0   0   0   0    0   0   \n",
       "1     0    0   0   0        0            0    0   0   0   0    0   0   \n",
       "2     0    0   0   0        0            0    0   0   0   0    0   0   \n",
       "3     0    0   0   0        0            0    0   0   0   0    0   0   \n",
       "4     0    0   0   0        0            0    0   0   0   0    0   0   \n",
       "\n",
       "   16 years  17  18  19  1967  1980s  1989  1990  1996  1998  1999  1st  20  \\\n",
       "0         0   0   0   0     0      0     0     0     0     0     0    0   0   \n",
       "1         0   0   0   0     0      0     0     0     0     0     0    0   0   \n",
       "2         0   0   0   0     0      0     0     0     0     0     0    0   0   \n",
       "3         0   0   0   0     0      0     0     0     0     0     0    0   0   \n",
       "4         0   0   0   0     0      0     0     0     0     0     0    0   0   \n",
       "\n",
       "   20 year  20 years  200  2000  2003  2005  2006  2008  2009  2010  2012  \\\n",
       "0        0         0    0     0     0     0     0     0     0     0     0   \n",
       "1        0         0    0     0     0     0     0     0     0     0     0   \n",
       "2        0         0    0     0     0     0     0     0     0     0     0   \n",
       "3        0         0    0     0     0     0     0     0     0     0     0   \n",
       "4        0         0    0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   2013  2014  2015  2016  2017  2018  2018 lego  2019  2020  20th  \\\n",
       "0     0     0     0     0     0     0          0     0     0     0   \n",
       "1     0     0     0     0     0     0          0     0     0     0   \n",
       "2     0     0     0     0     0     0          0     0     0     0   \n",
       "3     0     0     0     0     0     0          0     0     0     0   \n",
       "4     0     0     0     0     0     0          0     0     0     0   \n",
       "\n",
       "   20th anniversary  20th anniversary sets  21  22  23  24  25  250  26  27  \\\n",
       "0                 0                      0   0   0   0   0   0    0   0   0   \n",
       "1                 0                      0   0   0   0   0   0    0   0   0   \n",
       "2                 0                      0   0   0   0   0   0    0   0   0   \n",
       "3                 0                      0   0   0   0   0   0    0   0   0   \n",
       "4                 0                      0   0   0   0   0   0    0   0   0   \n",
       "\n",
       "   28  2nd  30  300  32  34  35  3d  40  400  41  45  4th  50  5000  501st  \\\n",
       "0   0    0   0    0   0   0   0   0   0    0   0   0    0   0     0      0   \n",
       "1   0    0   0    0   0   0   0   0   0    0   0   0    0   0     0      0   \n",
       "2   0    0   0    0   0   0   0   0   0    0   0   0    0   0     0      0   \n",
       "3   0    0   0    0   0   0   0   0   0    0   0   0    0   0     0      0   \n",
       "4   0    0   0    0   0   0   0   0   0    0   0   0    0   0     0      0   \n",
       "\n",
       "   55  59  5th  60  64  66  70  75  75105  75131  75155  75179  75181  75189  \\\n",
       "0   0   0    0   0   0   0   0   0      0      0      0      0      0      0   \n",
       "1   0   0    0   0   0   0   0   0      0      0      0      0      0      0   \n",
       "2   0   0    0   0   0   0   0   0      0      0      0      0      0      0   \n",
       "3   0   0    0   0   0   0   0   0      0      0      0      0      0      0   \n",
       "4   0   0    0   0   0   0   0   0      0      0      0      0      0      0   \n",
       "\n",
       "   75190  75191  75192  75211  75222  76  80  800  80s  90  90s  90s kids  \\\n",
       "0      0      0      0      0      0   0   0    0    0   0    0         0   \n",
       "1      0      0      0      0      0   0   0    0    0   0    0         0   \n",
       "2      0      0      0      0      0   0   0    0    0   0    0         0   \n",
       "3      0      0      0      0      0   0   0    0    0   0    0         0   \n",
       "4      0      0      0      0      0   0   0    0    0   0    0         0   \n",
       "\n",
       "   911  99  able  absolute  absolutely  access  accident  accidentally  \\\n",
       "0    0   0     0         0           0       0         0             0   \n",
       "1    0   0     0         0           0       0         0             0   \n",
       "2    0   0     0         0           0       0         0             0   \n",
       "3    0   0     0         0           0       0         0             0   \n",
       "4    0   0     0         0           0       0         0             0   \n",
       "\n",
       "   according  account  accounts  accurate  accused  achieved  achievement  \\\n",
       "0          0        0         0         0        0         0            0   \n",
       "1          0        0         0         0        0         0            0   \n",
       "2          0        0         0         0        0         0            0   \n",
       "3          0        0         0         0        0         0            0   \n",
       "4          0        0         0         0        0         0            0   \n",
       "\n",
       "   act  act scene  action  actor  actual  actually  ad  adam  adam west  add  \\\n",
       "0    0          0       0      0       0         0   0     0          0    0   \n",
       "1    0          0       0      0       0         0   0     0          0    0   \n",
       "2    0          0       0      0       0         0   0     0          0    0   \n",
       "3    0          0       0      0       0         0   0     0          0    0   \n",
       "4    0          0       0      0       0         0   0     0          0    0   \n",
       "\n",
       "   added  addiction  adding  addition  addition collection  additions  \\\n",
       "0      0          0       0         0                    0          0   \n",
       "1      0          0       0         0                    0          0   \n",
       "2      0          0       0         0                    0          0   \n",
       "3      0          0       0         0                    0          0   \n",
       "4      0          0       0         0                    0          0   \n",
       "\n",
       "   admiral  adorable  adult  advanced  advent  advent calendar  adventures  \\\n",
       "0        0         0      0         0       0                0           0   \n",
       "1        0         0      0         0       0                0           0   \n",
       "2        0         0      0         0       0                0           0   \n",
       "3        0         0      0         0       0                0           0   \n",
       "4        0         0      0         0       0                0           0   \n",
       "\n",
       "   advertising  advice  afford  afraid  african  age  ages  ago  agree  ahch  \\\n",
       "0            0       0       0       0        0    0     0    0      0     0   \n",
       "1            0       0       0       0        0    0     0    0      0     0   \n",
       "2            0       0       0       0        0    0     0    0      0     0   \n",
       "3            0       0       0       0        0    0     0    0      0     0   \n",
       "4            0       0       0       0        0    0     0    0      0     0   \n",
       "\n",
       "   ahead  aid  ain  air  airlines  airplane  airport  al  alarm  alaska  \\\n",
       "0      0    0    0    0         0         0        0   0      0       0   \n",
       "1      0    0    0    0         0         0        0   0      0       0   \n",
       "2      0    0    0    0         0         0        0   0      0       0   \n",
       "3      0    0    0    0         0         0        0   0      0       0   \n",
       "4      0    0    0    0         0         0        0   0      0       0   \n",
       "\n",
       "   album  album comments  alcohol  alderaan  alderaan playset  ali  alien  \\\n",
       "0      0               0        0         0                 0    0      0   \n",
       "1      0               0        0         0                 0    0      0   \n",
       "2      0               0        0         0                 0    0      0   \n",
       "3      0               0        0         0                 0    0      0   \n",
       "4      0               0        0         0                 0    0      0   \n",
       "\n",
       "   alive  alley  alliance  allow  allowance  allowed  alpha  alright  \\\n",
       "0      0      0         0      0          0        0      0        0   \n",
       "1      0      0         0      0          0        0      0        0   \n",
       "2      0      0         0      0          0        0      0        0   \n",
       "3      0      0         0      0          0        0      0        0   \n",
       "4      0      0         0      0          0        0      0        0   \n",
       "\n",
       "   alternate  alternate build  alternative  ama  amazing  amazing lego  \\\n",
       "0          0                0            0    0        0             0   \n",
       "1          0                0            0    0        0             0   \n",
       "2          0                0            0    0        0             0   \n",
       "3          0                0            0    0        0             0   \n",
       "4          0                0            0    0        0             0   \n",
       "\n",
       "   amazon  america  america 2016  american  americans  amigos  anakin  \\\n",
       "0       0        0             0         0          0       0       0   \n",
       "1       0        0             0         0          0       0       0   \n",
       "2       0        0             0         0          0       0       0   \n",
       "3       0        0             0         0          0       0       0   \n",
       "4       0        0             0         0          0       0       0   \n",
       "\n",
       "   ancient  android  angeles  anger  angle  angry  animal  animals  animated  \\\n",
       "0        0        0        0      0      0      0       0        0         0   \n",
       "1        0        0        0      0      0      0       0        0         0   \n",
       "2        0        0        0      0      0      0       0        0         0   \n",
       "3        0        0        0      0      0      0       0        0         0   \n",
       "4        0        0        0      0      0      0       0        0         0   \n",
       "\n",
       "   animation  anniversary  anniversary sets  anniversary slave  announce  \\\n",
       "0          0            0                 0                  0         0   \n",
       "1          0            0                 0                  0         0   \n",
       "2          0            0                 0                  0         0   \n",
       "3          0            0                 0                  0         0   \n",
       "4          0            0                 0                  0         0   \n",
       "\n",
       "   announced  announcement  announces  anon  answer  anti  ants  anybody  \\\n",
       "0          0             0          0     0       0     0     0        0   \n",
       "1          0             0          0     0       0     0     0        0   \n",
       "2          0             0          0     0       0     0     0        0   \n",
       "3          0             0          0     0       0     0     0        0   \n",
       "4          0             0          0     0       0     0     0        0   \n",
       "\n",
       "   anybody know  anybody remember  anymore  anyways  ap  apart  apartment  \\\n",
       "0             0                 0        0        0   0      0          0   \n",
       "1             0                 0        0        0   0      0          0   \n",
       "2             0                 0        0        0   0      0          0   \n",
       "3             0                 0        0        0   0      0          0   \n",
       "4             0                 0        0        0   0      0          0   \n",
       "\n",
       "   apocalypse  apocalyptic  apollo  apologize  app  apparently  appeal  \\\n",
       "0           0            0       0          0    0           0       0   \n",
       "1           0            0       0          0    0           0       0   \n",
       "2           0            0       0          0    0           0       0   \n",
       "3           0            0       0          0    0           0       0   \n",
       "4           0            0       0          0    0           0       0   \n",
       "\n",
       "   appear  apple  appreciate  appreciated  approaches  appropriate  apr  \\\n",
       "0       0      0           0            0           0            0    0   \n",
       "1       0      0           0            0           0            0    0   \n",
       "2       0      0           0            0           0            0    0   \n",
       "3       0      0           0            0           0            0    0   \n",
       "4       0      0           0            0           0            0    0   \n",
       "\n",
       "   apr 2019  april  april 2019  april fools  aquarium  arab  arabia  arc  \\\n",
       "0         0      0           0            0         0     0       0    0   \n",
       "1         0      0           0            0         0     0       0    0   \n",
       "2         0      0           0            0         0     0       0    0   \n",
       "3         0      0           0            0         0     0       0    0   \n",
       "4         0      0           0            0         0     0       0    0   \n",
       "\n",
       "   arc 170  arcade  arcade machines  architect  architecture  area  aren  \\\n",
       "0        0       0                0          0             0     0     0   \n",
       "1        0       0                0          0             0     0     0   \n",
       "2        0       0                0          0             0     0     0   \n",
       "3        0       0                0          0             0     0     0   \n",
       "4        0       0                0          0             0     0     0   \n",
       "\n",
       "   arizona  arm  armed  armor  arms  army  arrest  arrested  arrived  \\\n",
       "0        0    0      0      0     0     0       0         0        0   \n",
       "1        0    0      0      0     0     0       0         0        0   \n",
       "2        0    0      0      0     0     0       0         0        0   \n",
       "3        0    0      0      0     0     0       0         0        0   \n",
       "4        0    0      0      0     0     0       0         0        0   \n",
       "\n",
       "   arrived today  art  article  artist  ask  asked  asking  asks  asleep  ass  \\\n",
       "0              0    0        0       0    0      0       0     0       0    0   \n",
       "1              0    0        0       0    0      0       0     0       0    0   \n",
       "2              0    0        0       0    0      0       0     0       0    0   \n",
       "3              0    0        0       0    0      0       0     0       0    0   \n",
       "4              0    0        0       0    0      0       0     0       0    0   \n",
       "\n",
       "   assault  asshole  astromech  attack  attempt  attention  august  aunt  \\\n",
       "0        0        0          0       0        0          0       0     0   \n",
       "1        0        0          0       0        0          0       0     0   \n",
       "2        0        0          0       0        0          0       0     0   \n",
       "3        0        0          0       0        0          0       0     0   \n",
       "4        0        0          0       0        0          0       0     0   \n",
       "\n",
       "   aurora  austin  australia  australian  autism  automatic  autumn  \\\n",
       "0       0       0          0           0       0          0       0   \n",
       "1       0       0          0           0       0          0       0   \n",
       "2       0       0          0           0       0          0       0   \n",
       "3       0       0          0           0       0          0       0   \n",
       "4       0       0          0           0       0          0       0   \n",
       "\n",
       "   availability  available  avengers  avengers endgame  avengers infinity  \\\n",
       "0             0          0         0                 0                  0   \n",
       "1             0          0         0                 0                  0   \n",
       "2             0          0         0                 0                  0   \n",
       "3             0          0         0                 0                  0   \n",
       "4             0          0         0                 0                  0   \n",
       "\n",
       "   avengers infinity war  average  awakens  awakens review  award  awards  \\\n",
       "0                      0        0        0               0      0       0   \n",
       "1                      0        0        0               0      0       0   \n",
       "2                      0        0        0               0      0       0   \n",
       "3                      0        0        0               0      0       0   \n",
       "4                      0        0        0               0      0       0   \n",
       "\n",
       "   awareness  away  awesome  awesome lego  awhile  aww  babies  baby  \\\n",
       "0          0     0        0             0       0    0       0     0   \n",
       "1          0     0        0             0       0    0       0     0   \n",
       "2          0     0        0             0       0    0       0     0   \n",
       "3          0     0        0             0       0    0       0     0   \n",
       "4          0     0        0             0       0    0       0     0   \n",
       "\n",
       "   background  backlog  backwards  backyard  bacon  bad  bad ass  bad boy  \\\n",
       "0           0        0          0         0      0    0        0        0   \n",
       "1           0        0          0         0      0    0        0        0   \n",
       "2           0        0          0         0      0    0        0        0   \n",
       "3           0        0          0         0      0    0        0        0   \n",
       "4           0        0          0         0      0    0        0        0   \n",
       "\n",
       "   bad quality  badass  bag  bags  bakery  balcony  ball  balls  ban  banana  \\\n",
       "0            0       0    0     0       0        0     0      0    0       0   \n",
       "1            0       0    0     0       0        0     0      0    0       0   \n",
       "2            0       0    0     0       0        0     0      0    0       0   \n",
       "3            0       0    0     0       0        0     0      0    0       0   \n",
       "4            0       0    0     0       0        0     0      0    0       0   \n",
       "\n",
       "   banana scale  band  bang  bank  banksy  banned  bans  bar  barbie  barc  \\\n",
       "0             0     0     0     0       0       0     0    0       0     0   \n",
       "1             0     0     0     0       0       0     0    0       0     0   \n",
       "2             0     0     0     0       0       0     0    0       0     0   \n",
       "3             0     0     0     0       0       0     0    0       0     0   \n",
       "4             0     0     0     0       0       0     0    0       0     0   \n",
       "\n",
       "   barc speeder  barcelona  bardstown  bardstown ky  barnes  barry  bars  \\\n",
       "0             0          0          0             0       0      0     0   \n",
       "1             0          0          0             0       0      0     0   \n",
       "2             0          0          0             0       0      0     0   \n",
       "3             0          0          0             0       0      0     0   \n",
       "4             0          0          0             0       0      0     0   \n",
       "\n",
       "   base  base moc  baseball  based  basement  basically  basketball  bass  \\\n",
       "0     0         0         0      0         0          0           0     0   \n",
       "1     0         0         0      0         0          0           0     0   \n",
       "2     0         0         0      0         0          0           0     0   \n",
       "3     0         0         0      0         0          0           0     0   \n",
       "4     0         0         0      0         0          0           0     0   \n",
       "\n",
       "   bat  batcave  bathroom  batman  batman movie  batmobile  battle  \\\n",
       "0    0        0         0       0             0          0       0   \n",
       "1    0        0         0       0             0          0       0   \n",
       "2    0        0         0       0             0          0       0   \n",
       "3    0        0         0       0             0          0       0   \n",
       "4    0        0         0       0             0          0       0   \n",
       "\n",
       "   battle droid  battle pack  battle packs  battlefront  battlefront moc  \\\n",
       "0             0            0             0            0                0   \n",
       "1             0            0             0            0                0   \n",
       "2             0            0             0            0                0   \n",
       "3             0            0             0            0                0   \n",
       "4             0            0             0            0                0   \n",
       "\n",
       "   battlepack  bay  bb  beach  bean  bear  beard  beast  beatles  beats  \\\n",
       "0           0    0   0      0     0     0      0      0        0      0   \n",
       "1           0    0   0      0     0     0      0      0        0      0   \n",
       "2           0    0   0      0     0     0      0      0        0      0   \n",
       "3           0    0   0      0     0     0      0      0        0      0   \n",
       "4           0    0   0      0     0     0      0      0        0      0   \n",
       "\n",
       "   beautiful  beauty  bed  beer  beetle  begin  beginning  begins  behold  \\\n",
       "0          0       0    0     0       0      0          0       0       0   \n",
       "1          0       0    0     0       0      0          0       0       0   \n",
       "2          0       0    0     0       0      0          0       0       0   \n",
       "3          0       0    0     0       0      0          0       0       0   \n",
       "4          0       0    0     0       0      0          0       0       0   \n",
       "\n",
       "   believe  bell  belonged  belongs  ben  bernie  bernie sanders  bespin  \\\n",
       "0        0     0         0        0    0       0               0       0   \n",
       "1        0     0         0        0    0       0               0       0   \n",
       "2        0     0         0        0    0       0               0       0   \n",
       "3        0     0         0        0    0       0               0       0   \n",
       "4        0     0         0        0    0       0               0       0   \n",
       "\n",
       "   best  best friend  best friends  best lego  best picture  best place  \\\n",
       "0     0            0             0          0             0           0   \n",
       "1     0            0             0          0             0           0   \n",
       "2     0            0             0          0             0           0   \n",
       "3     0            0             0          0             0           0   \n",
       "4     0            0             0          0             0           0   \n",
       "\n",
       "   best thing  best war  best war stream  best way  betrayal  betrayal cloud  \\\n",
       "0           0         0                0         0         0               0   \n",
       "1           0         0                0         0         0               0   \n",
       "2           0         0                0         0         0               0   \n",
       "3           0         0                0         0         0               0   \n",
       "4           0         0                0         0         0               0   \n",
       "\n",
       "   betrayal cloud city  better  beware  bf  bible  bieber  big  big fan  \\\n",
       "0                    0       0       0   0      0       0    0        0   \n",
       "1                    0       0       0   0      0       0    0        0   \n",
       "2                    0       0       0   0      0       0    0        0   \n",
       "3                    0       0       0   0      0       0    0        0   \n",
       "4                    0       0       0   0      0       0    0        0   \n",
       "\n",
       "   big lego  bigger  biggest  bike  bike moc  bikes  biking  billion  billund  \\\n",
       "0         0       0        0     0         0      0       0        0        0   \n",
       "1         0       0        0     0         0      0       0        0        0   \n",
       "2         0       0        0     0         0      0       0        0        0   \n",
       "3         0       0        0     0         0      0       0        0        0   \n",
       "4         0       0        0     0         0      0       0        0        0   \n",
       "\n",
       "   bin  bird  birds  birth  birthday  bit  bitch  black  black friday  \\\n",
       "0    0     0      0      0         0    0      0      0             0   \n",
       "1    0     0      0      0         0    0      0      0             0   \n",
       "2    0     0      0      0         0    0      0      0             0   \n",
       "3    0     0      0      0         0    0      0      0             0   \n",
       "4    0     0      0      0         0    0      0      0             0   \n",
       "\n",
       "   black lion  blacktron  blade  blanket  bleeding  blind  block  blocks  \\\n",
       "0           0          0      0        0         0      0      0       0   \n",
       "1           0          0      0        0         0      0      0       0   \n",
       "2           0          0      0        0         0      0      0       0   \n",
       "3           0          0      0        0         0      0      0       0   \n",
       "4           0          0      0        0         0      0      0       0   \n",
       "\n",
       "   blog  blood  blow  blue  board  boat  bob  boba  boba fett  boca  body  \\\n",
       "0     0      0     0     0      0     0    0     0          0     0     0   \n",
       "1     0      0     0     0      0     0    0     0          0     0     0   \n",
       "2     0      0     0     0      0     0    0     0          0     0     0   \n",
       "3     0      0     0     0      0     0    0     0          0     0     0   \n",
       "4     0      0     0     0      0     0    0     0          0     0     0   \n",
       "\n",
       "   boi  bold  bomber  bonus  boobs  book  booked  books  boom  boost  boots  \\\n",
       "0    0     0       0      0      0     0       0      0     0      0      0   \n",
       "1    0     0       0      0      0     0       0      0     0      0      0   \n",
       "2    0     0       0      0      0     0       0      0     0      0      0   \n",
       "3    0     0       0      0      0     0       0      0     0      0      0   \n",
       "4    0     0       0      0      0     0       0      0     0      0      0   \n",
       "\n",
       "   borderlands  borderlands box  borderlands box art  bored  boring  born  \\\n",
       "0            0                0                    0      0       0     0   \n",
       "1            0                0                    0      0       0     0   \n",
       "2            0                0                    0      0       0     0   \n",
       "3            0                0                    0      0       0     0   \n",
       "4            0                0                    0      0       0     0   \n",
       "\n",
       "   boss  boston  bot  bothered  bots  bottle  bought  bought new  bought set  \\\n",
       "0     0       0    0         0     0       0       0           0           0   \n",
       "1     0       0    0         0     0       0       0           0           0   \n",
       "2     0       0    0         0     0       0       0           0           0   \n",
       "3     0       0    0         0     0       0       0           0           0   \n",
       "4     0       0    0         0     0       0       0           0           0   \n",
       "\n",
       "   bounty  bounty hunter  bounty hunters  bowl  box  boxes  boy  boyfriend  \\\n",
       "0       0              0               0     0    0      0    0          0   \n",
       "1       0              0               0     0    0      0    0          0   \n",
       "2       0              0               0     0    0      0    0          0   \n",
       "3       0              0               0     0    0      0    0          0   \n",
       "4       0              0               0     0    0      0    0          0   \n",
       "\n",
       "   boys  brain  brand  brand new  brazil  bread  break  breakfast  breaking  \\\n",
       "0     0      0      0          0       0      0      0          0         0   \n",
       "1     0      0      0          0       0      0      0          0         0   \n",
       "2     0      0      0          0       0      0      0          0         0   \n",
       "3     0      0      0          0       0      0      0          0         0   \n",
       "4     0      0      0          0       0      0      0          0         0   \n",
       "\n",
       "   breaking bad  brick  brickfilm  brickhead  brickheadz  bricklink  bricks  \\\n",
       "0             0      0          0          0           0          1       0   \n",
       "1             0      0          0          0           0          0       0   \n",
       "2             0      0          0          0           0          0       0   \n",
       "3             0      0          0          0           0          0       0   \n",
       "4             0      0          0          0           0          0       0   \n",
       "\n",
       "   bricks lego  brickvault  bridge  bring  brings  british  bro  ...  \\\n",
       "0            0           0       0      0       0        0    0  ...   \n",
       "1            0           0       0      0       0        0    0  ...   \n",
       "2            0           0       0      0       0        0    0  ...   \n",
       "3            0           0       0      0       0        0    0  ...   \n",
       "4            0           0       0      0       0        0    0  ...   \n",
       "\n",
       "   think ve  thinking  thinks  tho  thomas  thor  thorin  thought  \\\n",
       "0         0         0       0    0       0     0       0        0   \n",
       "1         0         0       0    0       0     0       0        0   \n",
       "2         0         0       0    0       0     0       0        0   \n",
       "3         0         0       0    0       0     0       0        0   \n",
       "4         0         0       0    0       0     0       0        0   \n",
       "\n",
       "   thought cool  thought guys  thought like  thought post  thought share  \\\n",
       "0             0             0             0             0              0   \n",
       "1             0             0             0             0              0   \n",
       "2             0             0             0             0              0   \n",
       "3             0             0             0             0              0   \n",
       "4             0             0             0             0              0   \n",
       "\n",
       "   thoughts  thoughts lego  thousand  thousands  thrawn  thread  threw  \\\n",
       "0         0              0         0          0       0       0      0   \n",
       "1         0              0         0          0       0       0      0   \n",
       "2         0              0         0          0       0       0      0   \n",
       "3         0              0         0          0       0       0      0   \n",
       "4         0              0         0          0       0       0      0   \n",
       "\n",
       "   thrift  thrift store  thriller  throne  throne room  throw  throwing  tie  \\\n",
       "0       0             0         0       0            0      0         0    0   \n",
       "1       0             0         0       0            0      0         0    0   \n",
       "2       0             0         0       0            0      0         0    0   \n",
       "3       0             0         0       0            0      0         0    0   \n",
       "4       0             0         0       0            0      0         0    0   \n",
       "\n",
       "   tie fighter  tie fighters  tie interceptor  ties  tifu  til  tiles  till  \\\n",
       "0            0             0                0     0     0    0      0     0   \n",
       "1            0             0                0     0     0    0      0     0   \n",
       "2            0             0                0     0     0    0      0     0   \n",
       "3            0             0                0     0     0    0      0     0   \n",
       "4            0             0                0     0     0    0      0     0   \n",
       "\n",
       "   tim  tim goddard  time  time lapse  time lapse build  time picture  \\\n",
       "0    0            0     0           0                 0             0   \n",
       "1    0            0     0           0                 0             0   \n",
       "2    0            0     0           0                 0             0   \n",
       "3    0            0     0           0                 0             0   \n",
       "4    0            0     0           0                 0             0   \n",
       "\n",
       "   time posting  timelapse  timelapse build  times  tiny  tip  tips  tired  \\\n",
       "0             0          0                0      0     0    0     0      0   \n",
       "1             0          0                0      0     0    0     0      0   \n",
       "2             0          0                0      0     0    0     0      0   \n",
       "3             0          0                0      0     0    0     0      0   \n",
       "4             0          0                0      0     0    0     0      0   \n",
       "\n",
       "   titanfall  titanic  title  tlj  today  today haul  todays  toilet  tokyo  \\\n",
       "0          0        0      0    0      0           0       0       0      0   \n",
       "1          0        0      0    0      0           0       0       0      0   \n",
       "2          0        0      0    0      0           0       0       0      0   \n",
       "3          0        0      0    0      1           0       0       0      0   \n",
       "4          0        0      0    0      0           0       0       0      0   \n",
       "\n",
       "   told  tom  tomorrow  ton  tonight  tony  took  took ago  took days  \\\n",
       "0     0    0         0    0        0     0     0         0          0   \n",
       "1     0    0         0    0        0     0     0         0          0   \n",
       "2     0    0         0    0        0     0     0         0          0   \n",
       "3     0    0         0    0        0     0     0         0          0   \n",
       "4     0    0         0    0        0     0     0         0          0   \n",
       "\n",
       "   took lot  took lot time  took phone  took photo  took picture  tool  tooth  \\\n",
       "0         0              0           0           0             0     0      0   \n",
       "1         0              0           0           0             0     0      0   \n",
       "2         0              0           0           0             0     0      0   \n",
       "3         0              0           0           0             0     0      0   \n",
       "4         0              0           0           0             0     0      0   \n",
       "\n",
       "   torn  toronto  torso  total  totally  totally worth  touch  tough  tour  \\\n",
       "0     0        0      0      0        0              0      0      0     0   \n",
       "1     0        0      0      0        0              0      0      0     0   \n",
       "2     0        0      0      0        0              0      0      0     0   \n",
       "3     0        0      0      0        0              0      0      0     0   \n",
       "4     0        0      0      0        0              0      0      0     0   \n",
       "\n",
       "   tournament  tower  towers  town  toy  toy store  toys  track  tractor  \\\n",
       "0           0      0       0     0    0          0     0      0        0   \n",
       "1           0      0       0     0    0          0     0      0        0   \n",
       "2           0      0       0     0    0          0     0      0        0   \n",
       "3           0      0       0     0    0          0     0      0        0   \n",
       "4           0      0       0     0    0          0     0      0        0   \n",
       "\n",
       "   trade  traded  trading  traditional  traffic  trailer  train  training  \\\n",
       "0      0       0        0            0        0        0      0         0   \n",
       "1      0       0        0            0        0        0      0         0   \n",
       "2      0       0        0            0        0        0      0         0   \n",
       "3      0       0        0            0        0        0      0         0   \n",
       "4      0       0        0            0        0        0      0         0   \n",
       "\n",
       "   trandish  trans  transformation  transformers  transforming  transport  \\\n",
       "0         0      0               0             0             0          0   \n",
       "1         0      0               0             0             0          0   \n",
       "2         0      0               0             0             0          0   \n",
       "3         0      0               0             0             0          0   \n",
       "4         0      0               0             0             0          0   \n",
       "\n",
       "   trap  trapped  trash  travel  treat  treated  tree  tree planting  trees  \\\n",
       "0     0        0      0       0      0        0     0              0      0   \n",
       "1     0        0      0       0      0        0     0              0      0   \n",
       "2     0        0      0       0      0        0     0              0      0   \n",
       "3     0        0      0       0      0        0     0              0      0   \n",
       "4     0        0      0       0      0        0     0              0      0   \n",
       "\n",
       "   trench  trench run  trend  tribute  tried  tried make  tries  trigger  \\\n",
       "0       0           0      0        0      0           0      0        0   \n",
       "1       0           0      0        0      0           0      0        0   \n",
       "2       0           0      0        0      0           0      0        0   \n",
       "3       0           0      0        0      0           0      0        0   \n",
       "4       0           0      0        0      0           0      0        0   \n",
       "\n",
       "   trilogy  trip  triple  tron  troop  troop transport  trooper  \\\n",
       "0        0     0       0     0      0                0        0   \n",
       "1        0     0       0     0      0                0        0   \n",
       "2        0     0       0     0      0                0        0   \n",
       "3        0     0       0     0      0                0        0   \n",
       "4        0     0       0     0      0                0        0   \n",
       "\n",
       "   trooper battle  trooper battle pack  troopers  troopers meet  troops  \\\n",
       "0               0                    0         0              0       0   \n",
       "1               0                    0         0              0       0   \n",
       "2               0                    0         0              0       0   \n",
       "3               0                    0         0              0       0   \n",
       "4               0                    0         0              0       0   \n",
       "\n",
       "   trouble  troy  tru  truck  true  true love  true story  truly  trump  \\\n",
       "0        0     0    0      0     0          0           0      0      0   \n",
       "1        0     0    0      0     0          0           0      0      0   \n",
       "2        0     0    0      0     0          0           0      0      1   \n",
       "3        0     0    0      0     0          0           0      0      0   \n",
       "4        0     0    0      0     0          0           0      0      0   \n",
       "\n",
       "   trunk  trust  truth  try  try make  trying  tsm  tuesday  turkey  turn  \\\n",
       "0      0      0      0    0         0       0    0        0       0     0   \n",
       "1      0      0      0    0         0       0    0        0       0     0   \n",
       "2      0      0      0    0         0       0    0        0       0     0   \n",
       "3      0      0      0    0         0       0    0        0       0     0   \n",
       "4      0      0      0    0         0       0    0        0       0     0   \n",
       "\n",
       "   turned  turning  turns  turret  turtle  tv  tweet  twitter  type  types  \\\n",
       "0       0        0      0       0       0   0      0        0     0      0   \n",
       "1       0        0      0       0       0   0      0        0     0      0   \n",
       "2       0        0      0       0       0   0      0        0     0      0   \n",
       "3       0        0      0       0       0   0      0        0     0      0   \n",
       "4       0        0      0       0       0   0      0        0     0      0   \n",
       "\n",
       "   ucs  ucs falcon  ucs millenium  ucs millenium falcon  ucs millennium  \\\n",
       "0    0           0              0                     0               0   \n",
       "1    0           0              0                     0               0   \n",
       "2    0           0              0                     0               0   \n",
       "3    0           0              0                     0               0   \n",
       "4    0           0              0                     0               0   \n",
       "\n",
       "   ucs millennium falcon  ucs set  ucs sets  ucs slave  ucs wing  ugly  uk  \\\n",
       "0                      0        0         0          0         0     0   0   \n",
       "1                      0        0         0          0         0     0   0   \n",
       "2                      0        0         0          0         0     0   0   \n",
       "3                      0        0         0          0         0     0   0   \n",
       "4                      0        0         0          0         0     0   0   \n",
       "\n",
       "   ult  ultimate  ultimate collector  ultimate collector series  ultra  \\\n",
       "0    0         0                   0                          0      0   \n",
       "1    0         0                   0                          0      0   \n",
       "2    0         0                   0                          0      0   \n",
       "3    0         0                   0                          0      0   \n",
       "4    0         0                   0                          0      0   \n",
       "\n",
       "   ultron  unboxing  uncle  understand  underwater  unfinished  unikitty  \\\n",
       "0       0         0      0           0           0           0         0   \n",
       "1       0         0      0           0           0           0         0   \n",
       "2       0         0      0           0           0           0         0   \n",
       "3       0         0      1           0           0           0         0   \n",
       "4       0         0      0           0           0           0         0   \n",
       "\n",
       "   unique  unit  united  united states  universe  university  unknown  unless  \\\n",
       "0       0     0       0              0         0           0        0       0   \n",
       "1       0     0       0              0         0           0        0       0   \n",
       "2       0     0       0              0         0           0        0       0   \n",
       "3       0     0       0              0         0           0        0       0   \n",
       "4       0     0       0              0         0           0        0       0   \n",
       "\n",
       "   unlimited  unlock  unlocked  unopened  unpopular  unpopular opinion  \\\n",
       "0          0       0         0         0          0                  0   \n",
       "1          0       0         0         0          0                  0   \n",
       "2          0       0         0         0          0                  0   \n",
       "3          0       0         0         0          0                  0   \n",
       "4          0       0         0         0          0                  0   \n",
       "\n",
       "   unsure  upcoming  update  updated  upgrade  upgraded  upper  upvote  \\\n",
       "0       0         0       0        0        0         0      0       0   \n",
       "1       0         0       0        0        0         0      0       0   \n",
       "2       0         0       0        0        0         0      0       0   \n",
       "3       0         0       0        0        0         0      0       0   \n",
       "4       0         0       0        0        0         0      0       0   \n",
       "\n",
       "   upvotes  usa  usd  use  used  useless  user  users  uses  using  usual  \\\n",
       "0        0    0    0    0     0        0     0      0     0      0      0   \n",
       "1        0    0    0    0     0        0     0      0     0      0      0   \n",
       "2        0    0    0    0     0        0     0      0     0      0      0   \n",
       "3        0    0    0    0     0        0     0      0     0      0      0   \n",
       "4        0    0    0    0     0        0     0      0     0      0      0   \n",
       "\n",
       "   usually  utah  v2  vacation  vader  vader bust  vader castle  vaders  \\\n",
       "0        0     0   0         0      0           0             0       0   \n",
       "1        0     0   0         0      0           0             0       0   \n",
       "2        0     0   0         0      0           0             0       0   \n",
       "3        0     0   0         0      0           0             0       0   \n",
       "4        0     0   0         0      0           0             0       0   \n",
       "\n",
       "   valentine  valentine day  valley  valuable  value  valve  van  vancouver  \\\n",
       "0          0              0       0         0      0      0    0          0   \n",
       "1          0              0       0         0      0      0    0          0   \n",
       "2          0              0       0         0      0      0    0          0   \n",
       "3          0              0       0         0      0      0    0          0   \n",
       "4          0              0       0         0      0      0    0          0   \n",
       "\n",
       "   ve  ve bought  ve got  ve heard  ve just  ve seen  ve taken  ve working  \\\n",
       "0   0          0       0         0        0        0         0           0   \n",
       "1   0          0       0         0        0        0         0           0   \n",
       "2   0          0       0         0        0        0         0           0   \n",
       "3   0          0       0         0        0        0         0           0   \n",
       "4   0          0       0         0        0        0         0           0   \n",
       "\n",
       "   vegas  vehicle  vehicles  venator  venator moc  venom  version  vet  vhs  \\\n",
       "0      0        0         0        0            0      0        0    0    0   \n",
       "1      0        0         0        0            0      0        0    0    0   \n",
       "2      0        0         0        0            0      0        0    0    0   \n",
       "3      0        0         0        0            0      0        0    0    0   \n",
       "4      0        0         0        0            0      0        0    0    0   \n",
       "\n",
       "   video  video game  video lego  videos  vietnam  view  views  village  \\\n",
       "0      0           0           0       0        0     0      0        0   \n",
       "1      0           0           0       0        0     0      0        0   \n",
       "2      0           0           0       0        0     0      0        0   \n",
       "3      0           0           0       0        0     0      0        0   \n",
       "4      0           0           0       0        0     0      0        0   \n",
       "\n",
       "   vintage  violence  vip  vip points  virginia  virginia living  \\\n",
       "0        0         0    0           0         0                0   \n",
       "1        0         0    0           0         0                0   \n",
       "2        0         0    0           0         0                0   \n",
       "3        0         0    0           0         0                0   \n",
       "4        0         0    0           0         0                0   \n",
       "\n",
       "   virginia living museum  virus  vision  visit  visited  visiting  voice  \\\n",
       "0                       0      0       0      0        0         0      0   \n",
       "1                       0      0       0      0        0         0      0   \n",
       "2                       0      0       0      0        0         0      0   \n",
       "3                       0      0       0      0        0         0      0   \n",
       "4                       0      0       0      0        0         0      0   \n",
       "\n",
       "   vol  voltron  volume  vonreg  vote  voted  voter  votes  voting  vs  \\\n",
       "0    0        0       0       0     0      0      0      0       0   0   \n",
       "1    0        0       0       0     0      0      0      0       0   0   \n",
       "2    0        0       0       0     0      0      0      0       0   0   \n",
       "3    0        0       0       0     0      0      0      0       0   0   \n",
       "4    0        0       0       0     0      0      0      0       0   0   \n",
       "\n",
       "   vs new  vs tsm  vulture  wa  wait  wait build  waiting  waiting line  wake  \\\n",
       "0       0       0        0   0     0           0        0             0     0   \n",
       "1       0       0        0   0     0           0        0             0     0   \n",
       "2       0       0        0   0     0           0        0             0     0   \n",
       "3       0       0        0   0     0           0        0             0     0   \n",
       "4       0       0        0   0     0           0        0             0     0   \n",
       "\n",
       "   wal  wal mart  walk  walked  walker  walkers  walking  walks  wall  \\\n",
       "0    0         0     0       0       0        0        0      0     0   \n",
       "1    0         0     0       0       0        0        0      0     0   \n",
       "2    0         0     0       0       0        0        0      0     0   \n",
       "3    0         0     0       0       0        0        0      0     0   \n",
       "4    0         0     0       0       0        0        0      0     0   \n",
       "\n",
       "   wall trees  wallet  wallpaper  walls  walmart  wan  wan kenobi  wanna  \\\n",
       "0           0       0          0      0        0    0           0      0   \n",
       "1           0       0          0      0        0    0           0      0   \n",
       "2           0       0          0      0        0    0           0      0   \n",
       "3           0       0          0      0        0    0           0      0   \n",
       "4           0       0          0      0        0    0           0      0   \n",
       "\n",
       "   want  want build  want make  wanted  wanted know  wanted share  wanting  \\\n",
       "0     0           0          0       0            0             0        0   \n",
       "1     0           0          0       0            0             0        0   \n",
       "2     0           0          0       0            0             0        0   \n",
       "3     0           0          0       0            0             0        0   \n",
       "4     0           0          0       0            0             0        0   \n",
       "\n",
       "   wants  wants photo  war  war stream  war stream mega  ward  warfare  \\\n",
       "0      0            0    0           0                0     0        0   \n",
       "1      0            0    0           0                0     0        0   \n",
       "2      0            0    0           0                0     0        0   \n",
       "3      0            0    0           0                0     0        0   \n",
       "4      0            0    0           0                0     0        0   \n",
       "\n",
       "   warning  warrior  wars  wars 2017  wars 20th  wars 20th anniversary  \\\n",
       "0        0        0     0          0          0                      0   \n",
       "1        0        0     0          0          0                      0   \n",
       "2        0        0     0          0          0                      0   \n",
       "3        0        0     0          0          0                      0   \n",
       "4        0        0     0          0          0                      0   \n",
       "\n",
       "   wars advent  wars advent calendar  wars best  wars best war  \\\n",
       "0            0                     0          0              0   \n",
       "1            0                     0          0              0   \n",
       "2            0                     0          0              0   \n",
       "3            0                     0          0              0   \n",
       "4            0                     0          0              0   \n",
       "\n",
       "   wars collection  wars complete  wars complete saga  wars darth  wars echo  \\\n",
       "0                0              0                   0           0          0   \n",
       "1                0              0                   0           0          0   \n",
       "2                0              0                   0           0          0   \n",
       "3                0              0                   0           0          0   \n",
       "4                0              0                   0           0          0   \n",
       "\n",
       "   wars echo squadron  wars episode  wars fans  wars force  \\\n",
       "0                   0             0          0           0   \n",
       "1                   0             0          0           0   \n",
       "2                   0             0          0           0   \n",
       "3                   0             0          0           0   \n",
       "4                   0             0          0           0   \n",
       "\n",
       "   wars force awakens  wars game  wars imperial  wars jedi  wars lego  \\\n",
       "0                   0          0              0          0          0   \n",
       "1                   0          0              0          0          0   \n",
       "2                   0          0              0          0          0   \n",
       "3                   0          0              0          0          0   \n",
       "4                   0          0              0          0          0   \n",
       "\n",
       "   wars lego collection  wars legos  wars rebels  wars resistance  wars set  \\\n",
       "0                     0           0            0                0         0   \n",
       "1                     0           0            0                0         0   \n",
       "2                     0           0            0                0         0   \n",
       "3                     0           0            0                0         0   \n",
       "4                     0           0            0                0         0   \n",
       "\n",
       "   wars sets  wars story  wars ucs  wars video  wash  washing  washington  \\\n",
       "0          0           0         0           0     0        0           0   \n",
       "1          0           0         0           0     0        0           0   \n",
       "2          0           0         0           0     0        0           0   \n",
       "3          0           0         0           0     0        0           0   \n",
       "4          0           0         0           0     0        0           0   \n",
       "\n",
       "   wasn  watch  watched  watching  water  wave  waves  way  way home  wayne  \\\n",
       "0     0      0        0         0      0     0      0    0         0      0   \n",
       "1     0      0        0         0      0     0      0    0         0      0   \n",
       "2     0      0        0         0      0     0      0    0         0      0   \n",
       "3     0      0        0         0      0     0      0    0         0      0   \n",
       "4     0      0        0         0      0     0      0    0         0      0   \n",
       "\n",
       "   wayne manor  ways  weapon  weapons  wear  wearing  weather  web  website  \\\n",
       "0            0     0       0        0     0        0        0    0        0   \n",
       "1            0     0       0        0     0        0        0    0        0   \n",
       "2            0     0       0        0     0        0        0    0        0   \n",
       "3            0     0       0        0     0        0        0    0        0   \n",
       "4            0     0       0        0     0        0        0    0        0   \n",
       "\n",
       "   websites  wedding  wednesday  week  weekend  weeks  weeks ago  weight  \\\n",
       "0         0        0          0     0        0      0          0       0   \n",
       "1         0        0          0     0        0      0          0       0   \n",
       "2         0        0          0     0        0      0          0       0   \n",
       "3         0        0          0     0        0      0          0       0   \n",
       "4         0        0          0     0        1      0          0       0   \n",
       "\n",
       "   weird  welcome  welp  went  werewolf  west  wet  whale  whales  wheel  \\\n",
       "0      0        0     0     0         0     0    0      0       0      0   \n",
       "1      0        0     0     0         0     0    0      0       0      0   \n",
       "2      0        0     0     0         0     0    0      0       0      0   \n",
       "3      0        0     0     0         0     0    0      0       0      0   \n",
       "4      0        0     0     0         0     0    0      0       0      0   \n",
       "\n",
       "   wheelchair  wheels  whisky  whisky distillery  whisky distillery bardstown  \\\n",
       "0           0       0       0                  0                            0   \n",
       "1           0       0       0                  0                            0   \n",
       "2           0       0       0                  0                            0   \n",
       "3           0       0       0                  0                            0   \n",
       "4           0       0       0                  0                            0   \n",
       "\n",
       "   white  white house  white whale  wide  wife  wife got  wifi  wild  willie  \\\n",
       "0      0            0            0     0     0         0     0     0       0   \n",
       "1      0            0            0     0     0         0     0     0       0   \n",
       "2      0            0            0     0     0         0     0     0       0   \n",
       "3      0            0            0     0     0         0     0     0       0   \n",
       "4      0            0            0     0     0         0     0     0       0   \n",
       "\n",
       "   wily  win  wind  window  windows  wing  wing moc  wing starfighter  wings  \\\n",
       "0     0    0     0       0        0     0         0                 0      0   \n",
       "1     0    0     0       0        0     0         0                 0      0   \n",
       "2     0    0     0       0        0     0         0                 0      0   \n",
       "3     0    0     0       0        0     0         0                 0      0   \n",
       "4     0    0     0       0        0     0         0                 0      0   \n",
       "\n",
       "   wins  winter  wip  wish  wolves  woman  women  women nasa  won  wonder  \\\n",
       "0     0       0    0     0       0      0      0           0    0       0   \n",
       "1     0       0    0     0       0      0      0           0    0       0   \n",
       "2     0       0    0     0       0      0      0           0    0       0   \n",
       "3     0       0    0     0       0      0      0           0    0       0   \n",
       "4     0       0    0     0       0      0      0           0    0       0   \n",
       "\n",
       "   wonderful  wondering  wood  wooden  word  words  work  work progress  \\\n",
       "0          0          0     0       0     0      0     0              0   \n",
       "1          0          0     0       0     0      0     0              0   \n",
       "2          0          0     0       0     0      0     0              0   \n",
       "3          0          0     0       0     0      0     0              0   \n",
       "4          0          0     0       0     0      0     0              0   \n",
       "\n",
       "   worked  worker  workers  working  working lego  works  world  world war  \\\n",
       "0       0       0        0        0             0      0      0          0   \n",
       "1       0       0        0        0             0      0      0          0   \n",
       "2       0       0        0        0             0      0      0          0   \n",
       "3       0       0        0        0             0      1      0          0   \n",
       "4       0       0        0        0             0      0      0          0   \n",
       "\n",
       "   worlds  worse  worst  worth  wouldn  wow  write  writing  written  wrong  \\\n",
       "0       0      0      0      0       0    0      0        0        0      0   \n",
       "1       0      0      0      0       0    0      0        0        0      0   \n",
       "2       0      0      0      0       0    0      0        0        0      0   \n",
       "3       0      0      0      0       0    0      0        0        0      0   \n",
       "4       0      0      0      0       0    0      0        0        0      0   \n",
       "\n",
       "   wrote  wtf  ww2  wwii  www  xbox  xd  xi  xmas  xpost  ya  yard  yard sale  \\\n",
       "0      0    0    0     0    0     0   0   0     0      0   0     0          0   \n",
       "1      0    0    0     0    0     0   0   0     0      0   0     0          0   \n",
       "2      0    0    0     0    0     0   0   0     0      0   0     0          0   \n",
       "3      0    0    0     0    0     0   0   0     0      0   0     0          0   \n",
       "4      0    0    0     0    0     0   0   0     0      0   0     0          0   \n",
       "\n",
       "   yavin  yeah  year  year ago  year old  year old boy  year old son  years  \\\n",
       "0      0     0     0         0         0             0             0      0   \n",
       "1      0     0     0         0         0             0             0      0   \n",
       "2      0     0     0         0         0             0             0      0   \n",
       "3      0     0     0         0         0             0             0      0   \n",
       "4      0     0     0         0         0             0             0      0   \n",
       "\n",
       "   years ago  years later  years old  yellow  yes  yesterday  yo  yoda  \\\n",
       "0          0            0          0       0    0          0   0     0   \n",
       "1          0            0          0       0    0          0   0     0   \n",
       "2          0            0          0       0    0          0   0     0   \n",
       "3          0            0          0       0    0          0   0     0   \n",
       "4          0            0          0       0    0          0   0     0   \n",
       "\n",
       "   yoda hut  york  young  younger  youtube  youtube channel  yr  yr old  \\\n",
       "0         0     0      0        0        0                0   0       0   \n",
       "1         0     0      0        0        0                0   0       0   \n",
       "2         0     0      0        0        0                0   0       0   \n",
       "3         0     0      0        0        0                0   0       0   \n",
       "4         0     0      0        0        0                0   0       0   \n",
       "\n",
       "   zelda  zero  zombie  zone  zoo  \n",
       "0      0     0       0     0    0  \n",
       "1      0     0       0     0    0  \n",
       "2      0     0       0     0    0  \n",
       "3      0     0       0     0    0  \n",
       "4      0     0       0     0    0  \n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8656345565749235\n",
      "The testing score: 0.8395108903324418\n",
      "The best parameters from the grid search: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'learning_rate': 1.0, 'n_estimators': 5}\n",
      "The best score from the grid seacrh: 0.7799120795107034\n",
      "Generating predictions\n",
      "time: 264.489 seconds\n",
      "time: 4 minutes, 24.489 seconds\n",
      "Accuracy score 0.8395108903324418  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1089                 220\n",
      "Actually_Positive                 200                1108 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1309\n",
      "           1       0.83      0.85      0.84      1308\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2617\n",
      "   macro avg       0.84      0.84      0.84      2617\n",
      "weighted avg       0.84      0.84      0.84      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB()],\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw   # Python Reddit API Wrapper\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thank you for your function, Heather\n",
    "\n",
    "def metrics(y_test, y_predict):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Actually_Negative', 'Actually_Positive'], \n",
    "                            columns=['Predicted_Negative', 'Predicted_Positive']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.read_csv('data_pos_class.csv')\n",
    "# positive_df.head()\n",
    "\n",
    "negative_df = pd.read_csv('data_neg_class.csv')\n",
    "negative_df['class'] = negative_df['class'].map(lambda x:0)\n",
    "# negative_df.head()\n",
    "\n",
    "df = pd.concat([positive_df, negative_df], axis=0)\n",
    "df.shape\n",
    "\n",
    "X = df['title']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    We are attempting to tighten the variance.  We are of the opinion that we are only playing with the different parameters to see what happens.  This is really good practice for shaping me mind, and helping me learn how the models behave differently in certain circumstances.  In this model, the bag returned a model that is predicting slightly more false negatives, but also less false positives.  But, the overall accuracy is about the same as above.  The biggest takeaway difference thought is that the GridSearch decided that a better score was possible (a more accurate model) when it took bootstrapped over the features, taking only half of them at each construction.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 22.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8767201834862385\n",
      "The testing score: 0.8467711119602599\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-63bc70e2938e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The training score: {gs_bag.score(df_train, y_train)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The testing score: {gs_bag.score(df_test, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The best parameters from the grid search: {gs.best_params_}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The best score from the grid seacrh: {gs.best_score_}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [10],\n",
    "    'max_features'  : [0.5, 1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters from the grid search: {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'max_features': 0.5, 'n_estimators': 10}\n",
      "The best score from the grid seacrh: 0.8297018348623854\n",
      "Generating predictions\n"
     ]
    }
   ],
   "source": [
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8467711119602599  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1162                 147\n",
      "Actually_Positive                 254                1054 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      1309\n",
      "           1       0.88      0.81      0.84      1308\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2617\n",
      "   macro avg       0.85      0.85      0.85      2617\n",
      "weighted avg       0.85      0.85      0.85      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    In the following we decided to increase the number of models being constructed at each step, and try bootstrapping over the features with a few other proportions.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8814984709480123\n",
      "The testing score: 0.8414214749713412\n",
      "The best parameters from the grid search: {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'max_features': 0.5, 'n_estimators': 10}\n",
      "The best score from the grid seacrh: 0.8249235474006116\n",
      "Generating predictions\n",
      "time: 1302.789 seconds\n",
      "time: 21 minutes, 42.789 seconds\n",
      "Accuracy score 0.8414214749713412  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1221                  88\n",
      "Actually_Positive                 327                 981 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      1309\n",
      "           1       0.92      0.75      0.83      1308\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2617\n",
      "   macro avg       0.85      0.84      0.84      2617\n",
      "weighted avg       0.85      0.84      0.84      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [10],\n",
    "    'max_features'  : [0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 17.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8891437308868502\n",
      "The testing score: 0.8471532288880398\n",
      "The best parameters from the grid search: {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'max_features': 0.5, 'n_estimators': 20}\n",
      "The best score from the grid seacrh: 0.829224006116208\n",
      "Generating predictions\n",
      "time: 1064.001 seconds\n",
      "time: 17 minutes, 44.001 seconds\n",
      "Accuracy score 0.8471532288880398  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1221                  88\n",
      "Actually_Positive                 312                 996 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1309\n",
      "           1       0.92      0.76      0.83      1308\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2617\n",
      "   macro avg       0.86      0.85      0.85      2617\n",
      "weighted avg       0.86      0.85      0.85      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [20],\n",
    "    'max_features'  : [0.5, 1]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 41.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.9011850152905199\n",
      "The testing score: 0.8418035918991211\n",
      "The best parameters from the grid search: {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'max_features': 1.0, 'n_estimators': 30}\n",
      "The best score from the grid seacrh: 0.8276949541284404\n",
      "Generating predictions\n",
      "time: 2590.725 seconds\n",
      "time: 43 minutes, 10.725 seconds\n",
      "Accuracy score 0.8418035918991211  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1221                  88\n",
      "Actually_Positive                 326                 982 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86      1309\n",
      "           1       0.92      0.75      0.83      1308\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2617\n",
      "   macro avg       0.85      0.84      0.84      2617\n",
      "weighted avg       0.85      0.84      0.84      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [30],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Next, we test the 4 models against each other to see which returns the best score.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8563646788990825\n",
      "The testing score: 0.8234619793656859\n",
      "The best parameters from the grid search: {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'max_features': 1.0, 'n_estimators': 1}\n",
      "The best score from the grid seacrh: 0.8156536697247706\n",
      "Generating predictions\n",
      "time: 95.754 seconds\n",
      "time: 1 minutes, 35.754 seconds\n",
      "Accuracy score 0.8234619793656859  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1060                 249\n",
      "Actually_Positive                 213                1095 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1309\n",
      "           1       0.81      0.84      0.83      1308\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2617\n",
      "   macro avg       0.82      0.82      0.82      2617\n",
      "weighted avg       0.82      0.82      0.82      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=5000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [1],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Here we increase the number for max_features in count vectorizer (the number of tokens) to 10,000, just to see if we can get our accuracy up a bit.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8757645259938838\n",
      "The testing score: 0.8288116163546045\n",
      "The best parameters from the grid search: {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'max_features': 1.0, 'n_estimators': 1}\n",
      "The best score from the grid seacrh: 0.8220565749235474\n",
      "Generating predictions\n",
      "time: 174.949 seconds\n",
      "time: 2 minutes, 54.949 seconds\n",
      "Accuracy score 0.8288116163546045  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1051                 258\n",
      "Actually_Positive                 190                1118 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1309\n",
      "           1       0.81      0.85      0.83      1308\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      2617\n",
      "   macro avg       0.83      0.83      0.83      2617\n",
      "weighted avg       0.83      0.83      0.83      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=10_000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [1],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Here, we increase the number of features again, expecting MultinomialNB to win out again, but with higher variance.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.891724006116208\n",
      "The testing score: 0.8418035918991211\n",
      "The best parameters from the grid search: {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'max_features': 1.0, 'n_estimators': 1}\n",
      "The best score from the grid seacrh: 0.8243501529051988\n",
      "Generating predictions\n",
      "time: 244.026 seconds\n",
      "time: 4 minutes, 4.026 seconds\n",
      "Accuracy score 0.8418035918991211  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1118                 191\n",
      "Actually_Positive                 223                1085 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1309\n",
      "           1       0.85      0.83      0.84      1308\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2617\n",
      "   macro avg       0.84      0.84      0.84      2617\n",
      "weighted avg       0.84      0.84      0.84      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=15_000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [1],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Here, we increase the max_features in the tokenizer (CountVectorizer) to see if we can continue to increase our accuracy.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8941131498470948\n",
      "The testing score: 0.8391287734046619\n",
      "The best parameters from the grid search: {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'max_features': 1.0, 'n_estimators': 1}\n",
      "The best score from the grid seacrh: 0.8237767584097859\n",
      "Generating predictions\n",
      "time: 321.214 seconds\n",
      "time: 5 minutes, 21.214 seconds\n",
      "Accuracy score 0.8391287734046619  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1108                 201\n",
      "Actually_Positive                 220                1088 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      1309\n",
      "           1       0.84      0.83      0.84      1308\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2617\n",
      "   macro avg       0.84      0.84      0.84      2617\n",
      "weighted avg       0.84      0.84      0.84      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=20_000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [1],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Sadly, our accuracy didn't increase any, and in fact, the score on the testing set decreased, causing our variance to increase.  Now, we will attempt to increase the number of ngrams, to see what effect this has on the model.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Realizing that many phraises are common amoung lego builders, we increase the number of ngrams in an attempt to tune our model and increase accuracy even more.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.8846521406727829\n",
      "The testing score: 0.8261367978601452\n",
      "The best parameters from the grid search: {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'max_features': 1.0, 'n_estimators': 1}\n",
      "The best score from the grid seacrh: 0.8136467889908257\n",
      "Generating predictions\n",
      "time: 332.999 seconds\n",
      "time: 5 minutes, 32.999 seconds\n",
      "Accuracy score 0.8261367978601452  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1026                 283\n",
      "Actually_Positive                 172                1136 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      1309\n",
      "           1       0.80      0.87      0.83      1308\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      2617\n",
      "   macro avg       0.83      0.83      0.83      2617\n",
      "weighted avg       0.83      0.83      0.83      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=20_000, ngram_range=(1,4), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier(), MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [1],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    We choose to scale back the amount of data being trained on to 15_000 features, with at most 3-grams.  Here we will try and tighten the variance by actually ensembling.  We will set n_estimators = 30, and let the bag run again, understanding and expecting this to take a while.  Again, we are looking for a tighter fitting model, one that has less variance.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score: 0.9624426605504587\n",
      "The testing score: 0.8162017577378677\n",
      "The best parameters from the grid search: {'base_estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'max_features': 1.0, 'n_estimators': 30}\n",
      "The best score from the grid seacrh: 0.8044724770642202\n",
      "Generating predictions\n",
      "time: 1566.657 seconds\n",
      "time: 26 minutes, 6.657 seconds\n",
      "Accuracy score 0.8162017577378677  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                   Predicted_Negative  Predicted_Positive\n",
      "Actually_Negative                1125                 184\n",
      "Actually_Positive                 297                1011 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82      1309\n",
      "           1       0.85      0.77      0.81      1308\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2617\n",
      "   macro avg       0.82      0.82      0.82      2617\n",
      "weighted avg       0.82      0.82      0.82      2617\n",
      "\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=15_000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [RandomForestClassifier()],#, MultinomialNB(), None, LogisticRegression()],\n",
    "    'n_estimators'  : [30],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue size = 4.5>\n",
    "    Let's try the previous calculation using the Naive Bayes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlining the bagging parameters.\n",
      "Instantiate a baggin model\n",
      "Instantiating a grid search\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-37de2e19f7fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                       verbose = 1)\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mgs_bag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The training score: {gs_bag.score(df_train, y_train)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The testing score: {gs_bag.score(df_test, y_test)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 378\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# We are using a bagging algorithm because our model is high variance.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state = 28,\n",
    "                                                    stratify = y,\n",
    "                                                    test_size = 0.20)\n",
    "\n",
    "# Let's instantiate a CountVectorizor, and build a model to see what we get.\n",
    "cvec = CountVectorizer(max_features=15_000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "# training dataframe\n",
    "df_train = pd.DataFrame(cvec.fit_transform(X_train).toarray(),\n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "# testing dataframe\n",
    "df_test = pd.DataFrame(cvec.transform(X_test).toarray(),\n",
    "                      columns=cvec.get_feature_names())\n",
    "\n",
    "print('Outlining the bagging parameters.')\n",
    "bag_params = {\n",
    "    'base_estimator': [LogisticRegression()],\n",
    "    'n_estimators'  : [50],\n",
    "    'max_features'  : [1.0]\n",
    "}\n",
    "\n",
    "print(f'Instantiate a baggin model')\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "print('Instantiating a grid search')\n",
    "gs_bag = GridSearchCV(bag,\n",
    "                      param_grid=bag_params,\n",
    "                      verbose = 1)\n",
    "\n",
    "gs_bag.fit(df_train, y_train)\n",
    "print(f'The training score: {gs_bag.score(df_train, y_train)}')\n",
    "print(f'The testing score: {gs_bag.score(df_test, y_test)}')\n",
    "print(f'The best parameters from the grid search: {gs_bag.best_params_}')\n",
    "print(f'The best score from the grid seacrh: {gs_bag.best_score_}')\n",
    "\n",
    "print('Generating predictions')\n",
    "preds = gs_bag.predict(df_test)\n",
    "\n",
    "end_time = round(time.time() - start_time, 3)\n",
    "print(f'time: {end_time} seconds')\n",
    "end_time_minutes = int(end_time/ 60)\n",
    "end_time_seconds = round(end_time % 60, 3)\n",
    "\n",
    "print(f'time: {end_time_minutes} minutes, {end_time_seconds} seconds')\n",
    "metrics(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
